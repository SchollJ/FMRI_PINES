[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notes on (f)MRI analysis",
    "section": "",
    "text": "This is a collection of notes on (f)MRI analysis. We will try to cover both techincal aspects on how to run an analysis, mainly using CRNL resources and cluster and also some theoretical aspects on how to interpret the results as well as key references. The aim is to have a file that i will keep both my code and notes."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#intro-and-glossary",
    "href": "index.html#intro-and-glossary",
    "title": "Notes on (f)MRI analysis",
    "section": "Intro and Glossary",
    "text": "Intro and Glossary\nIn this document we will try to build a document on how to visually inspect the MRIQC and fMRIPrep visual outputs.\nFor this are going to use several resources:\nMain Resource will be the paper that these notes are attached to –&gt; (Provins et al., 2023)\nBut also see:\n\nhttps://www.youtube.com/watch?v=In6Dez_uuxQ&t=1s –&gt; video toturial on youtube on how to set up and interpret fmriqc by Matt Defenderfer of UAB research computing\nhttps://sarenseeley.github.io/BIDS-fmriprep-MRIQC.html#Usage30 –&gt; Very helpful and well structured notes (main inspiration for this document) from Saren Seeley on BIDS, FMRIQC and fmriprep\nhttps://docs.google.com/document/d/1TE6ZWzNg8cDpvL4Vu0VGOZQLXkQ88Fa59AORzN01Avk/edit –&gt; google doc produced by Saren Seeley on how to read fmriprep output with the contribution of Oscar Esteban\n(Provins et al., 2022) –&gt; interpretation of the extended carpet plot in fmriprep and fmriqc + corresponding nuisance regressor\n\n\nQuality assessment (QA):\n\nFocuses on ensuring the research workflow produces data of “sufficient quality” (e.g identifying a structures artifact caused by an environmental condition that can be actioned upon so that it doesn’t replicate prospectively in future acquisitions).\n\n\n\nQuality control (QC):\n\nExcludes poor-quality data from the dataset so that they do not continue through the research workflow and potentially bias the results\n\n–&gt; QA/QC checkpoints are mostly unstandardized and typically involve the screening of the images one by one.\n–&gt; Raters: individual researchers that repeatedly screening data"
  },
  {
    "objectID": "index.html#methods",
    "href": "index.html#methods",
    "title": "Notes on (f)MRI analysis",
    "section": "Methods",
    "text": "Methods\n\nAssessing the unprocessed data using the MRIQC visual reports\nAssess the results with minimal preprocessing using hte fMRIPrep visual reports.\n\n\nAssessment of quality aspects and exclusion criteria\n\nAll based on the visual inspection of the individual MRIQCC and fMRIPrep eports, so they are all qualitative."
  },
  {
    "objectID": "MRIQC_BOLD.html",
    "href": "MRIQC_BOLD.html",
    "title": "BOLD data",
    "section": "",
    "text": "Because no BOLD signal originates from the air surrounding the head, the background should not contain visible structures.\nHowever, signal can spill into the background through several imaging processes:\n- [Aliasing ghosts](#aliasing-ghosts)\n\n- Spillover originating from moving and blinking eyes\n    \n- Bulkhead motion\n    \nWhere to find:\n\nBackground noise panel (mainly here)\nStandard deviation map view\n\nWhat to look for:\n\n\n\n\n\nCaused by B0 field non-uniformity.\n\nInserting an object in the scanner perturbs the nominal B0 field, which should be constant all across the FoV\nTissue boundaries produce steps of deviation from the nominal B0 field, which are larger where the air is close to tissues\nThe signal is slightly diplaced from the sampling grid along the phase encoding axis leading to susceptibility distortions.\n\n\nWhere to find:\nOn the BOLD average panel\nIn two different ways\n\nAs a signal drop out - that is a region where the signal vanishes\n– Signal drop - outs often appers close to the brain - air interfaces\n\nVentromedial prefrontal cortex\nAnterior part of the prefrontal cortex\nRegion next to ear cavities\n\nAs brain distortions\n\nWhat to do to correct: can by corrected by the susceptibility distortion correction implemented in FMRIPrep as long there is as a corresponding filed map\nTherefore, susceptibility distortions does not necessarily mean an exclusion criteria\nWhat to look for:\n\n\n\n\n–&gt; A ghost is a type of structured noise that appears as shifted and faintly repeated versions of the main object, usually in the phase encoding direction.\nFor several reasons:\n\nsignal instability between pulse cycle repetitions\nthe particular strategy of echo-planar imaging to record the k-space during acquisition\n\nOften exacerbated by within-volume had motion.\n–&gt; Where to find:\n                1) In the background noise visualisation\n                2) Bold average view\nWhat to look for:\n  Important Tip: Increase the screen’s brightness as low brightness makes this artifact harder to see!\n\n\n\nWhenever the object’s dimensions exceed the defined field-of-view (FOV).\n- It is visibe as a piece of the head (usually the skull) being folded over on the opposite extreme of the image\n    \n- Exclude subjects based on the observation of a wrap-around only if the folded region contained or overlapped in the cortex.\n    \nWhere to find:**  \n\nBackground noise visualisation –&gt; The clearest\nBOLD average\nStandard deviation map\n\nWhat to look for:  Important Tip: Increase the screen’s brightness as low brightness makes this artifact harder to see!\n\n\n\nCarpet plot is a tool to visualise changes in voxel intensity throughout an fMRI scan. The idea is to plot voxel time series in close spatial proximity so that the eye notes temporal coincidence.\nBoth in MRIQC and FMRIPrep\nCrown area: correspond’s to voxels located on a closed band around the brain’s outer edge. As those voxels are outside the brain, we do not expect any signal there, meaning that if some signal is observed, we can interpret it as artifactual.\nA strongly structured crown region in the carpet plot is a sign that the artifacts are compromising the fmri scanner. Could be due to: 1. Motions peaks 2. Periodic motion (e.g. respiration) 3. Coil failure 4. Drift of unknown origin\nFinding temporal patterns similar in gray matter areas and simultaneously in regions of no interest (for instance, cerebrospinal fluid or the crown) indicates the presence of artifacts, typically derived from head motion.\nIf the planned analysis specifies noise regression techniques based on information from these regions of no interest [which is standard and recommended (Ciric et al., 2017)], the risk of removing signals with neural origins is high, and affected scans should be excluded.\nWhat to look for: \n\n\n\nSeveral time series to support the interpretation of the carpet plot. The slice-wise z-standardized signal average is useful for detecting sudden “spikes” in the average intensity of single slices of BOLD scans.\n\nWhen paired with the motion traces, it is possible to determine whether these spikes are caused by:\n\nMotion –&gt; Spikes caused by motion typically affect several or all slices\nOr by possible problems with the scanner (e.g. white-pixel noise) –&gt; Spikes caused by white - pixel noise affect only one slice and are generally more acute\nWhite-pixel noise is generally caused by some small pieces of metal in the scan room or a loose screw on the scanner that accumulates energy and then discharges randomly.In the image domain, it manifests as an abrupt signal intensity change in one slice at one time point.\nFor resting-state data, you discard BOLD scans containing these spikes regardless of their physical origin (motion vs. white-pixel noise) because correlation analyses are likely biased by such peaks. Task data analyses are typically more robust to this particular artifact.\n\n\nWhat to look for:\n\n\n\n\n\nThe sagittal view of the sd map might show vertical strike patterns that extend hyperintensities through the whole sagittal plan\nExclude all images that showcase these patterns\n\nWhat to look for:\n\n\n\n\n\nSuch mistakes result in the brain image not being correctly visualized and preprocessed, with axes either being flipped (e.g. the anterior part of the brain is labeled as posterior) or switched (e.g. axial slices are interpreted as coronal ones).\n\nWhat to look for:",
    "crumbs": [
      "MRIQC",
      "BOLD visual reports"
    ]
  },
  {
    "objectID": "MRIQC.html",
    "href": "MRIQC.html",
    "title": "MRIQC",
    "section": "",
    "text": "Interpretation on the visual inspection of the individual MRIQC\nFor more information see the documentation of the MRQC\nNote: The artifacts yielding exclusion are pointed using red arrows, while the artifacts not yielding exclusion are pointed using green arrows.\nTo be added:\n\nIQMs individual level\nVisual inspection to group level\nIQMs group level",
    "crumbs": [
      "MRIQC"
    ]
  },
  {
    "objectID": "MRIQC_BOLD.html#exclusion-criteria",
    "href": "MRIQC_BOLD.html#exclusion-criteria",
    "title": "BOLD data",
    "section": "",
    "text": "Because no BOLD signal originates from the air surrounding the head, the background should not contain visible structures.\nHowever, signal can spill into the background through several imaging processes:\n- [Aliasing ghosts](#aliasing-ghosts)\n\n- Spillover originating from moving and blinking eyes\n    \n- Bulkhead motion\n    \nWhere to find:\n\nBackground noise panel (mainly here)\nStandard deviation map view\n\nWhat to look for:\n\n\n\n\n\nCaused by B0 field non-uniformity.\n\nInserting an object in the scanner perturbs the nominal B0 field, which should be constant all across the FoV\nTissue boundaries produce steps of deviation from the nominal B0 field, which are larger where the air is close to tissues\nThe signal is slightly diplaced from the sampling grid along the phase encoding axis leading to susceptibility distortions.\n\n\nWhere to find:\nOn the BOLD average panel\nIn two different ways\n\nAs a signal drop out - that is a region where the signal vanishes\n– Signal drop - outs often appers close to the brain - air interfaces\n\nVentromedial prefrontal cortex\nAnterior part of the prefrontal cortex\nRegion next to ear cavities\n\nAs brain distortions\n\nWhat to do to correct: can by corrected by the susceptibility distortion correction implemented in FMRIPrep as long there is as a corresponding filed map\nTherefore, susceptibility distortions does not necessarily mean an exclusion criteria\nWhat to look for:\n\n\n\n\n–&gt; A ghost is a type of structured noise that appears as shifted and faintly repeated versions of the main object, usually in the phase encoding direction.\nFor several reasons:\n\nsignal instability between pulse cycle repetitions\nthe particular strategy of echo-planar imaging to record the k-space during acquisition\n\nOften exacerbated by within-volume had motion.\n–&gt; Where to find:\n                1) In the background noise visualisation\n                2) Bold average view\nWhat to look for:\n  Important Tip: Increase the screen’s brightness as low brightness makes this artifact harder to see!\n\n\n\nWhenever the object’s dimensions exceed the defined field-of-view (FOV).\n- It is visibe as a piece of the head (usually the skull) being folded over on the opposite extreme of the image\n    \n- Exclude subjects based on the observation of a wrap-around only if the folded region contained or overlapped in the cortex.\n    \nWhere to find:**  \n\nBackground noise visualisation –&gt; The clearest\nBOLD average\nStandard deviation map\n\nWhat to look for:  Important Tip: Increase the screen’s brightness as low brightness makes this artifact harder to see!\n\n\n\nCarpet plot is a tool to visualise changes in voxel intensity throughout an fMRI scan. The idea is to plot voxel time series in close spatial proximity so that the eye notes temporal coincidence.\nBoth in MRIQC and FMRIPrep\nCrown area: correspond’s to voxels located on a closed band around the brain’s outer edge. As those voxels are outside the brain, we do not expect any signal there, meaning that if some signal is observed, we can interpret it as artifactual.\nA strongly structured crown region in the carpet plot is a sign that the artifacts are compromising the fmri scanner. Could be due to: 1. Motions peaks 2. Periodic motion (e.g. respiration) 3. Coil failure 4. Drift of unknown origin\nFinding temporal patterns similar in gray matter areas and simultaneously in regions of no interest (for instance, cerebrospinal fluid or the crown) indicates the presence of artifacts, typically derived from head motion.\nIf the planned analysis specifies noise regression techniques based on information from these regions of no interest [which is standard and recommended (Ciric et al., 2017)], the risk of removing signals with neural origins is high, and affected scans should be excluded.\nWhat to look for: \n\n\n\nSeveral time series to support the interpretation of the carpet plot. The slice-wise z-standardized signal average is useful for detecting sudden “spikes” in the average intensity of single slices of BOLD scans.\n\nWhen paired with the motion traces, it is possible to determine whether these spikes are caused by:\n\nMotion –&gt; Spikes caused by motion typically affect several or all slices\nOr by possible problems with the scanner (e.g. white-pixel noise) –&gt; Spikes caused by white - pixel noise affect only one slice and are generally more acute\nWhite-pixel noise is generally caused by some small pieces of metal in the scan room or a loose screw on the scanner that accumulates energy and then discharges randomly.In the image domain, it manifests as an abrupt signal intensity change in one slice at one time point.\nFor resting-state data, you discard BOLD scans containing these spikes regardless of their physical origin (motion vs. white-pixel noise) because correlation analyses are likely biased by such peaks. Task data analyses are typically more robust to this particular artifact.\n\n\nWhat to look for:\n\n\n\n\n\nThe sagittal view of the sd map might show vertical strike patterns that extend hyperintensities through the whole sagittal plan\nExclude all images that showcase these patterns\n\nWhat to look for:\n\n\n\n\n\nSuch mistakes result in the brain image not being correctly visualized and preprocessed, with axes either being flipped (e.g. the anterior part of the brain is labeled as posterior) or switched (e.g. axial slices are interpreted as coronal ones).\n\nWhat to look for:",
    "crumbs": [
      "MRIQC",
      "BOLD visual reports"
    ]
  },
  {
    "objectID": "resources/Visual Reports MRIQC Unprocessed BOLD data + small intro.html",
    "href": "resources/Visual Reports MRIQC Unprocessed BOLD data + small intro.html",
    "title": "Visual Reports MRIQC Unprocessed BOLD data + small intro",
    "section": "",
    "text": "In this document we will try to build a document on how to visually inspect the MRIQC and fMRIPrep visual outputs.\nFor this are going to use several resources:\nMain Resource will be the paper that these notes are attached to –&gt; (Provins et al., 2023)\nBut also see:\n\nhttps://www.youtube.com/watch?v=In6Dez_uuxQ&t=1s –&gt; video toturial on youtube on how to set up and interpret fmriqc by Matt Defenderfer of UAB research computing\nhttps://sarenseeley.github.io/BIDS-fmriprep-MRIQC.html#Usage30 –&gt; Very helpful and well structured notes (main inspiration for this document) from Saren Seeley on BIDS, FMRIQC and fmriprep\nhttps://docs.google.com/document/d/1TE6ZWzNg8cDpvL4Vu0VGOZQLXkQ88Fa59AORzN01Avk/edit –&gt; google doc produced by Saren Seeley on how to read fmriprep output with the contribution of Oscar Esteban\n(Provins et al., 2022) –&gt; interpretation of the extended carpet plot in fmriprep and fmriqc + corresponding nuisance regressor\n\n\n\n\nFocuses on ensuring the research workflow produces data of “sufficient quality” (e.g identifying a structures artifact caused by an environmental condition that can be actioned upon so that it doesn’t replicate prospectively in future acquisitions).\n\n\n\n\n\nExcludes poor-quality data from the dataset so that they do not continue through the research workflow and potentially bias the results\n\n--&gt; QA/QC checkpoints are mostly unstandardized and typically involve the screening of the images one by one.\n--&gt; Raters: individual researchers that repeatedly screening data\n\n\n\n\n\nAssessing the unprocessed data using the MRIQC visual reports\nAssess the results with minimal preprocessing using hte fMRIPrep visual reports.\n\n\n\n\nAll based on the visual inspection of the individual MRIQCC and fMRIPrep eports, so they are all qualitative."
  },
  {
    "objectID": "resources/Visual Reports MRIQC Unprocessed BOLD data + small intro.html#intro-and-glossary",
    "href": "resources/Visual Reports MRIQC Unprocessed BOLD data + small intro.html#intro-and-glossary",
    "title": "Visual Reports MRIQC Unprocessed BOLD data + small intro",
    "section": "",
    "text": "In this document we will try to build a document on how to visually inspect the MRIQC and fMRIPrep visual outputs.\nFor this are going to use several resources:\nMain Resource will be the paper that these notes are attached to –&gt; (Provins et al., 2023)\nBut also see:\n\nhttps://www.youtube.com/watch?v=In6Dez_uuxQ&t=1s –&gt; video toturial on youtube on how to set up and interpret fmriqc by Matt Defenderfer of UAB research computing\nhttps://sarenseeley.github.io/BIDS-fmriprep-MRIQC.html#Usage30 –&gt; Very helpful and well structured notes (main inspiration for this document) from Saren Seeley on BIDS, FMRIQC and fmriprep\nhttps://docs.google.com/document/d/1TE6ZWzNg8cDpvL4Vu0VGOZQLXkQ88Fa59AORzN01Avk/edit –&gt; google doc produced by Saren Seeley on how to read fmriprep output with the contribution of Oscar Esteban\n(Provins et al., 2022) –&gt; interpretation of the extended carpet plot in fmriprep and fmriqc + corresponding nuisance regressor\n\n\n\n\nFocuses on ensuring the research workflow produces data of “sufficient quality” (e.g identifying a structures artifact caused by an environmental condition that can be actioned upon so that it doesn’t replicate prospectively in future acquisitions).\n\n\n\n\n\nExcludes poor-quality data from the dataset so that they do not continue through the research workflow and potentially bias the results\n\n--&gt; QA/QC checkpoints are mostly unstandardized and typically involve the screening of the images one by one.\n--&gt; Raters: individual researchers that repeatedly screening data"
  },
  {
    "objectID": "resources/Visual Reports MRIQC Unprocessed BOLD data + small intro.html#methods",
    "href": "resources/Visual Reports MRIQC Unprocessed BOLD data + small intro.html#methods",
    "title": "Visual Reports MRIQC Unprocessed BOLD data + small intro",
    "section": "",
    "text": "Assessing the unprocessed data using the MRIQC visual reports\nAssess the results with minimal preprocessing using hte fMRIPrep visual reports.\n\n\n\n\nAll based on the visual inspection of the individual MRIQCC and fMRIPrep eports, so they are all qualitative."
  },
  {
    "objectID": "resources/Visual Reports of fMRIPrep.html#error-reports",
    "href": "resources/Visual Reports of fMRIPrep.html#error-reports",
    "title": "Visual Reports of fMRIPrep",
    "section": "Error reports",
    "text": "Error reports\n\nFirst check for the error reports at the very end of the html file"
  },
  {
    "objectID": "resources/Visual Reports of fMRIPrep.html#summary",
    "href": "resources/Visual Reports of fMRIPrep.html#summary",
    "title": "Visual Reports of fMRIPrep",
    "section": "Summary",
    "text": "Summary\n\nOverall summary of the pipeline –&gt; information about anatomical and functional images\n\nThis should much the options we defined on the script that we used to run fmriprep"
  },
  {
    "objectID": "resources/Visual Reports of fMRIPrep.html#anatomical-section",
    "href": "resources/Visual Reports of fMRIPrep.html#anatomical-section",
    "title": "Visual Reports of fMRIPrep",
    "section": "Anatomical Section",
    "text": "Anatomical Section\n\nBrain mask and brain tissue segmentation of the T1w\n\nA good overview of the surfaces as well as the brain masks created by Freesurfer\n\nWhite matter boundary is outlined in blue\nEstimated brain mask is outlined in red\nGrey matter boundary is outlined in magenda\n\n\nExample:\n[image]\n\nInaccurate brain mask (Provins et al., 2023)\n\nThe brain mask should closely follow the contour of the brain.\nAn inaccurate brain mask presents “bumps” surrounding high-intensity areas of signal outside of the cortex (e.g., a mask inclusding patches of he skull) and/or holes surrounding signal drop-out regions.\n\nError in brain tissue segmentation of T1w images (Provins et al., 2023)\n\nTo confirm the good quality of the segmentation verify that\n\nThe magenda contour accurately outline the ventricles\nThe blue contour followed the boundary between GM and WM\n\nExclusion criteria: inclusion of tissues other than the tissue of interest in the contour delineations\n\n\nExample:\n[image]\n\n\nSpatial normalization of the anatomical T1w reference\n\nA gif that if you hover your mouse over the image, the image will flicker between participant space and to the chosen template (e.g. here MNI152NLin6Asym space. –&gt; This can show you how well the native space was registered to the standard space overall\nFailure in normalization to MNI space (Provins et al., 2023)\n      –&gt; Normalization must be perfect\n      –&gt; To verify successful normalization assess the correct alignment of the following structures (in order of importance):\n        1) Ventricles\n        2) subcortical regions\n        3) corpus callosum\n        4) cerebellum\n        5) cortical gray matter (GM)\n        --&gt; Misalignment of 1,2 or 3: immediate exclusion\n        --&gt; For 5 a bit more loose because volumetric (image) registration may not resolve substantial inter-individual differences\n        --&gt; Any extreme stretching or distortion of the T1w image also indicates a failed normalization\n--&gt; Tip: Put your mouse at the edge of the participant brain, should be perfect when flickers1 between the 2 spaces (This is not the case for the MRIQC output that has only the 1st iteration while here the algorithm has multiple iteration and trying to optimize the procedure).\n--&gt; Tip: Make sure to check the alignment not only in the outlines of the brain (see above) but also in the internal structures such as the ventricles.\n--&gt; Tip: (From discussion with Gaëlle) Do not pay so much emphasis in image x=0 as it it difficult and errors must be expected\n\nExample:\n--&gt; add the gif here with the mouse on the edge\n\n\nSurface reconstruction\n\nWhite matter in blue\nPial surface in red\nThese are overlaid on the participant’s T1w image\nUsually you do not exclude data here except the reconstructed surfaces are extremely inaccurate but you should already have seen that in MRIQC"
  },
  {
    "objectID": "resources/Visual Reports of fMRIPrep.html#functional-section",
    "href": "resources/Visual Reports of fMRIPrep.html#functional-section",
    "title": "Visual Reports of fMRIPrep",
    "section": "Functional Section",
    "text": "Functional Section\n\nAlignment between the anatomical reference of the fieldmap and the target EPI\n\nAfter discussion with Gaëlle patterns like the one’s highlighted below are normal\n\n[image]\n\n\nSusceptibility distortion correction\n\na gif that shows before and after distortion correction\nNote that the correction is affected by the direction AP vs PA\nAny observation of susceptibility distortion artifacts leads to the exclusion of the scan\n\nExample:\n[image]\n\n\nCompCor by default in fmriprep\n\nData driven approach to  add nuisance regressors –&gt; if you want to use this approach check also the correlation heatmap\n\n\n\nAlignment of functional and anatomical MRI data (coregistration)\n\nCo - registration problem (Provins et al., 2023)\n\nCheck the alignment of image intensity edges and the anatomical landmarks (e.g. the ventricles and the corpus callosum) between the BOLD and the T1w images\n\n\n\n\nTime-series carpet plot and correlation matrices\n\nGS: Global Signal\nGSCSF: Global Signal of the Cerebral Spinal Fluid\nGSWM: Global Signal of the White Matter\n2 measures of motion\n\nDVARS\nFD: Framewise displacement\n\n\n--&gt; Changes in motion tend to be correlated with GS and it is up to us to decide if we include any of these vars in the model. In general DVARS and FD are good ways to account for signal caused by motion artifacts"
  },
  {
    "objectID": "resources/Visual Reports of fMRIPrep.html#important-note-smoothing-is-not-in-the-pipeline-of-fmriprep-therefore-it-is-a-step-that-has-to-be-executed-after-running-the-fmriprep-pipeline.",
    "href": "resources/Visual Reports of fMRIPrep.html#important-note-smoothing-is-not-in-the-pipeline-of-fmriprep-therefore-it-is-a-step-that-has-to-be-executed-after-running-the-fmriprep-pipeline.",
    "title": "Visual Reports of fMRIPrep",
    "section": "Important Note: Smoothing is not in the pipeline of fmriprep, therefore it is a step that has to be executed after running the fmriprep pipeline.",
    "text": "Important Note: Smoothing is not in the pipeline of fmriprep, therefore it is a step that has to be executed after running the fmriprep pipeline.\n\nSmoothing has been ommited by design –&gt; The fmriprep does not make assumption on how you are going to analyze your data\n\ne.g. Some MVPA studies do not do any smoothing at all before the first level analysis\n\nThe amount of smoothing is a matter of judgement\n\nExperiments that are focused on larger cortical areas, probably want to use larger smoothing kernels\n\n\n--&gt;Tip: Since we have multiple tasks with different goals, smoothing should be executed with this in mind and probably individually for each task/goal. When performing that use a prefix (e.g. smo0.8 or sth along those lines) in the name of the data so it is quite clear and easy to find what was the smoothing!"
  },
  {
    "objectID": "resources/Visual Reports of fMRIPrep.html#exclusion-criteria-of-pre-processed-data-based-on-fmriprep-visual-report",
    "href": "resources/Visual Reports of fMRIPrep.html#exclusion-criteria-of-pre-processed-data-based-on-fmriprep-visual-report",
    "title": "Visual Reports of fMRIPrep",
    "section": "Exclusion criteria of pre-processed data based on fMRIPrep visual report",
    "text": "Exclusion criteria of pre-processed data based on fMRIPrep visual report"
  },
  {
    "objectID": "resources/Visual Reports MRIQC unprocessed T1w data.html",
    "href": "resources/Visual Reports MRIQC unprocessed T1w data.html",
    "title": "Visual Reports MRIQC unprocessed T1w data",
    "section": "",
    "text": "Visual Reports MRIQC unprocessed T1w data\nIn this document we will make notes on how to interpret the visual reports of MRIQC specifically for T1w data.\n\nFor a small intro, resources and Glossary see: Visual Reports MRIQC Unprocessed BOLD data + small intro in the notes of this paper\n\nFor:\n\nArtifactual structures in the background\nSusceptibility distortion artifacts\n\nSignal drop-out\nBrain distortions\n\nAliasing ghost\nWrap-around that overlaps with the brain\nData formatting issues\n\n--&gt; the description is the same as the BOLD reports. For more details see document: Visual Reports MRIQC Unprocessed BOLD data + small intro in the notes of this paper\n--&gt; Note that normalization and co-registration are relative robust to structural images with mild artifacts, therefore it is not always absolute necessity to impose exclusion criteria on the unprocessed T1w images.\nExamples:\n[image]\n\nMotion - related and Gibbs ringing: Large head motion during the acquisition of T1w images often expresses itself with the appearance of concentric ripples throughout the scan\n--&gt; Gibbs ringing: is a consequence of the truncation of the Fourier series approximation and appears as multiple fine lines immediately adjacent and parallel to high contrast interfaces. But it is the same with subtle cases of motion related issues.\n--&gt; The ripples cause by motion generally span the whole brain and are primarily visible in the sagittal view fo MRIQC’s mosaic view\n\nFor an example see the above image: Figure S10E\n\nIntensity non-uniformity: is characterized by a smooth variation (low spatial frequency) of intensity throughout the brain caused by the strongel signal sensed in the proximity of coils.\n\nWhere –&gt; On the zoomed-in vie on the T1w image\nCan be a problem for automated processing methods that assume a type of tissue [e.g. white matter (WM)] is represented by voxels of similar intensities across the whole brain.\nAn extreme intensity non-uniformity can also be a sign of coil failure\n\n\nFor an example see the above image Figure S10F\n\nEye spillover: Eye movements may trigger the signal leakage from the eyes through the imaging axes with the lowest bandwidth (i.e., acquired faster), potentially overlapping signal from brain tissue.\n\nA strong signal leakage can however be noticeable on the zoomed-in view of the T1w image\nIn defaced data the leakage might not be visible\n\n\nFor an example see the above image Figure S10G\nOther Notes\nInterpretation of the visual reports of the T1w images based on (“Introduction to MRIQC [TRAIN-05-2022]”, 2022)\n\nZoomed-in mosaic view of the brain –&gt; zoomed in brain masks of the T1w images in a horzontal view\n\nWe want high contrast between the grey matter and the white matter\nWe also have to check for ringing artifacts\n\nBackground Noise\n\nYellow and green are areas with high background noise\nDark purple are areas with lwo background noise\n\n\nAreas like:\n        1) The teeth\n        2) Sinus cavities            –&gt; are areas with high background noise\n        3) Air canals\n[image]\nBut: whenever you get in the brain you don’t really want any noise, you want that all purple\n[image]\n--&gt; And same thing for the saggital view\n[image]"
  },
  {
    "objectID": "MRIQC_Anat.html",
    "href": "MRIQC_Anat.html",
    "title": "Anatomical data",
    "section": "",
    "text": "In this document we will make notes on how to interpret the visual reports of MRIQC specifically for T1w data.\n\n\nFor:\n\nArtifactual structures in the background\nSusceptibility distortion artifacts\n\nSignal drop-out\nBrain distortions\n\nAliasing ghost\nWrap-around that overlaps with the brain\nData formatting issues\n\n\nDescription is the same as the BOLD reports.\nNote that normalization and co-registration are relative robust to structural images with mild artifacts, therefore it is not always absolute necessity to impose exclusion criteria on the unprocessed T1w images.\n\nExamples:\n\n\n\n\nLarge head motion during the acquisition of T1w images often expresses itself with the appearance of concentric ripples throughout the scan\n\nGibbs ringing: is a consequence of the truncation of the Fourier series approximation and appears as multiple fine lines immediately adjacent and parallel to high contrast interfaces. But it is the same with subtle cases of motion related issues.\nThe ripples cause by motion generally span the whole brain and are primarily visible in the sagittal view fo MRIQC’s mosaic view\n\nFor an example see the above image: Figure S10E\n\n\n\n\nIs characterized by a smooth variation (low spatial frequency) of intensity throughout the brain caused by the strongel signal sensed in the proximity of coils.\n\nWhere: On the zoomed-in view on the T1w image\nCan be a problem for automated processing methods that assume a type of tissue [e.g. white matter (WM)] is represented by voxels of similar intensities across the whole brain.\nAn extreme intensity non-uniformity can also be a sign of coil failure\n\n\nFor an example see the above image Figure S10F\n\n\n\n\nEye movements may trigger the signal leakage from the eyes through the imaging axes with the lowest bandwidth (i.e., acquired faster), potentially overlapping signal from brain tissue.\n\nA strong signal leakage can however be noticeable on the zoomed-in view of the T1w image\nIn defaced data the leakage might not be visible\n\n\nFor an example see the above image Figure S10G"
  },
  {
    "objectID": "MRIQC_Anat.html#visual-reports-mriqc-unprocessed-t1w-data",
    "href": "MRIQC_Anat.html#visual-reports-mriqc-unprocessed-t1w-data",
    "title": "Anatomical data",
    "section": "",
    "text": "In this document we will make notes on how to interpret the visual reports of MRIQC specifically for T1w data.\n\n\nFor:\n\nArtifactual structures in the background\nSusceptibility distortion artifacts\n\nSignal drop-out\nBrain distortions\n\nAliasing ghost\nWrap-around that overlaps with the brain\nData formatting issues\n\n\nDescription is the same as the BOLD reports.\nNote that normalization and co-registration are relative robust to structural images with mild artifacts, therefore it is not always absolute necessity to impose exclusion criteria on the unprocessed T1w images.\n\nExamples:\n\n\n\n\nLarge head motion during the acquisition of T1w images often expresses itself with the appearance of concentric ripples throughout the scan\n\nGibbs ringing: is a consequence of the truncation of the Fourier series approximation and appears as multiple fine lines immediately adjacent and parallel to high contrast interfaces. But it is the same with subtle cases of motion related issues.\nThe ripples cause by motion generally span the whole brain and are primarily visible in the sagittal view fo MRIQC’s mosaic view\n\nFor an example see the above image: Figure S10E\n\n\n\n\nIs characterized by a smooth variation (low spatial frequency) of intensity throughout the brain caused by the strongel signal sensed in the proximity of coils.\n\nWhere: On the zoomed-in view on the T1w image\nCan be a problem for automated processing methods that assume a type of tissue [e.g. white matter (WM)] is represented by voxels of similar intensities across the whole brain.\nAn extreme intensity non-uniformity can also be a sign of coil failure\n\n\nFor an example see the above image Figure S10F\n\n\n\n\nEye movements may trigger the signal leakage from the eyes through the imaging axes with the lowest bandwidth (i.e., acquired faster), potentially overlapping signal from brain tissue.\n\nA strong signal leakage can however be noticeable on the zoomed-in view of the T1w image\nIn defaced data the leakage might not be visible\n\n\nFor an example see the above image Figure S10G"
  },
  {
    "objectID": "MRIQC_BOLD.html#other-notes-on-interpretation",
    "href": "MRIQC_BOLD.html#other-notes-on-interpretation",
    "title": "BOLD data",
    "section": "Other Notes on Interpretation",
    "text": "Other Notes on Interpretation\nFollowing notes are mainly from (“Introduction to MRIQC [TRAIN-05-2022] - YouTube,” n.d.).\n\nBold average\nIt gives you the Bold average, so it’s averaging all the volumes together and presenting them as this slices through that average.\n\n- What are you looking for is in the main area of the brain to see a high contrast between grey and white matter**\nBUT: Note that these images are not preprossessed so there is no distortion correction! So in an AP image as the one below if you see some smooshing at the front and some extension at the back that’s completely normal\n\nExample: (AP image)\n\n\n\nBold average\n\n\n\n\nStandard deviation map\n** It is the spread of the value of all the voxels over the entire time course**\ne.g. : When you are looking to at the sd of voxels that correspond to the eyes, these have high sd because the are constantly moving so the values are going to have a high spread.\n\n\n\n\n\n\nBut when you are in the brain what you want are low sd values!\nAlso, you get areas of high sd:\n\nalong the edges of the brain (due to slight movement that causes these voxels to have brain or CSF or skull or empty space)  \nand in some of the major blood vessels that go through the brain  \n\n\n\n\n\n\n\n\n\nFramewise Displacement (FD) [mm]\nThe absolute distance after motion that the brain moved from the beginning reference image (but note that no actual motion correction is saved at this point).\n\n0.2 mm cut -off, you get an idea on how many volumes when beyond this cut-off point, note that this is a pretty stringent cut-off score for FD\n\nExample:",
    "crumbs": [
      "MRIQC",
      "BOLD visual reports"
    ]
  },
  {
    "objectID": "MRIQC_Anat.html#other-notes-on-interpretation",
    "href": "MRIQC_Anat.html#other-notes-on-interpretation",
    "title": "Anatomical data",
    "section": "Other Notes on Interpretation",
    "text": "Other Notes on Interpretation\nInterpretation of the visual reports of the T1w images based on (“Introduction to MRIQC [TRAIN-05-2022] - YouTube,” n.d.)\n\nZoomed-in mosaic view of the brain\n\nZoomed in brain masks of the T1w images in a horzontal view\n\nWe want high contrast between the grey matter and the white matter\nWe also have to check for ringing artifacts\n\n\n\n\nBackground noise\n\nYellow and green are areas with high background noise\nDark purple are areas with lwo background noise\n\nAreas like:\n\nThe teeth\nSinus cavities\nAir canals\n\n\nAre areas with high background noise\n\nExample:\n\nBut: whenever you get in the brain you don’t really want any noise, you want that all purple\nExample:\n\nAnd same thing for the saggital view\nExample:\n\n(Note: After discussing with Gaëlle, the above examples are super super clean, and is not that usual to actually get so clean data, it’s ok)."
  },
  {
    "objectID": "fMRIPrep.html",
    "href": "fMRIPrep.html",
    "title": "fMRI preprocessing",
    "section": "",
    "text": "Based on:\n\n(“Introduction to MRIQC [TRAIN-05-2022] - YouTube,” n.d.)\n(Provins et al. 2023)\n(“fMRIPrep Tutorial #3: Examining the Preprocessed Data  Andy’s Brain Book 1.0 Documentation,” n.d.)\nNotes after my discussion with Gaëlle Leroux (CRNL) on 25/04/2024\n\nToDO:\n\nCheck the pdf that Gaëlle sent me named “Train your eyes” Alhtough, this is a resource generally for artifacts in structural and functional MRI data and not specifically for fMRIPrep, it might be useful to check it out to build some intuition on what to look for in the raw data.\n[ ]",
    "crumbs": [
      "fMRIPrep",
      "fMRI preprocessing"
    ]
  },
  {
    "objectID": "fMRIPrep_visual_reports.html",
    "href": "fMRIPrep_visual_reports.html",
    "title": "fMRIPrep visual reports",
    "section": "",
    "text": "First check for the error reports at the very end of the html file",
    "crumbs": [
      "fMRIPrep",
      "fMRIPrep visual reports"
    ]
  },
  {
    "objectID": "fMRIPrep_visual_reports.html#error-reports",
    "href": "fMRIPrep_visual_reports.html#error-reports",
    "title": "fMRIPrep visual reports",
    "section": "",
    "text": "First check for the error reports at the very end of the html file",
    "crumbs": [
      "fMRIPrep",
      "fMRIPrep visual reports"
    ]
  },
  {
    "objectID": "fMRIPrep_visual_reports.html#summary",
    "href": "fMRIPrep_visual_reports.html#summary",
    "title": "fMRIPrep visual reports",
    "section": "Summary",
    "text": "Summary\nOverall summary of the pipeline: information about anatomical and functional images\nThis should much the options we defined on the script that we used to run fmriprep",
    "crumbs": [
      "fMRIPrep",
      "fMRIPrep visual reports"
    ]
  },
  {
    "objectID": "fMRIPrep_visual_reports.html#anatomical-section",
    "href": "fMRIPrep_visual_reports.html#anatomical-section",
    "title": "fMRIPrep visual reports",
    "section": "Anatomical Section",
    "text": "Anatomical Section\n\nBrain mask and brain tissue segmentation of the T1w\n\nA good overview of the surfaces as well as the brain masks created by Freesurfer\n\nWhite matter boundary is outlined in blue\nEstimated brain mask is outlined in red\nGrey matter boundary is outlined in magenda\n\n\nExample:\n\n\n\nInaccurate brain mask\n\nThe brain mask should closely follow the contour of the brain.\nAn inaccurate brain mask presents “bumps” surrounding high-intensity areas of signal outside of the cortex (e.g., a mask inclusding patches of he skull) and/or holes surrounding signal drop-out regions.\n\n\n\nError in brain tissue segmentation of T1w images\n\nTo confirm the good quality of the segmentation verify that:\n\nThe magenda contour outline the ventricles\nThe blue contour followed the boundary between the white matter and the grey matter\n\nExclusion criteria: inclusion of tissue other than the tissue of interest in the contour delineations\n\nExample:\n\n\n\nSpatial normalization of the anatomical T1w reference\n\nA GIF in which if you hover your mouse over the image, the image will flicker between participant space and to the chosen template (e.g. here MNI152NLin6Asym space).\nThis can show you how well the native space was registered to the standard space overall\nFailure in normalization to MNI space\n\nNormalization must me perfect\n\nTo verify successful normalization assess the correct alignment of the following structures (in order of importance):\n\n\nVentricles\nSubcortical regions\nCorpus Callosum\nCerebellum\nCortical Grey Matter (GM)\n\n\nMisalignment of 1,2 or 3: immediate exclusion\nFor 5 a bit more loose because volumetric (image) registration may not resolve substantial inter-individual differences\nAny extreme stretching or distortion of the T1w image also indicates a failed normalization\n\nTip: Put your mouse at the edge of the participant brain, should be perfect when flickers1 between the 2 spaces (This is not the case for the MRIQC output that has only the 1st iteration while here the algorithm has multiple iteration and trying to optimize the procedure).\nTip: Make sure to check the alignment not only in the outlines of the brain (see above) but also in the internal structures such as the ventricles.\nTip: (From discussion with Gaëlle) Do not pay so much emphasis in image x=0 as it it difficult and errors must be expected\nExample:\n\n\n\nSurface reconstruction\n\nWhite matter in blue\nPial surface in red\nThese are overlaid on the participant’s T1w image\nUsually you do not exclude data here except the reconstructed surfaces are extremely inaccurate but you should already have seen that in MRIQC",
    "crumbs": [
      "fMRIPrep",
      "fMRIPrep visual reports"
    ]
  },
  {
    "objectID": "fMRIPrep_visual_reports.html#functional-section",
    "href": "fMRIPrep_visual_reports.html#functional-section",
    "title": "fMRIPrep visual reports",
    "section": "Functional Section",
    "text": "Functional Section\n\nAlignment between the anatomical reference of the fieldmap and the target EPI\n\nAfter discussion with Gaëlle patterns like the one’s highlighted below are normal\n\n\n\n\nSusceptibility distortion correction\n\nA GIF that shows before and after distortion correction\nNote that the correction is affected by the direction AP vs PA\nAny observation of susceptibility distortion artifacts leads to the exclusion of the scan\n\nExample:\n\n\n\nCompCor by default in fmriprep\n\nData driven approach to add nuisance regressors\nIf you want to use this approach check also the correlation heatmap\n\n\n\nAlignment of functional and anatomical MRI data (coregistration)\n\nCo - registration problem\n\nCheck the alignment of image intensity edges and the anatomical landmarks (e.g. the ventricles and the corpus callosum) between the BOLD and the T1w images\n\n\n\n\nTime-series carpet plot and correlation matrices\n\nGS: Global Signal\nGSCSF: Global Signal of the Cerebral Spinal Fluid\nGSWM: Global Signal of the White Matter\n2 measures of motion\n\nDVARS\nFD: Framewise displacement\n\nChanges in motion tend to be correlated with GS and it is up to us to decide if we include any of these vars in the model. In general DVARS and FD are good ways to account for signal caused by motion artifacts\n\n\n\nSmoothing\nImportant Note: Smoothing is not in the pipeline of fmriprep, therefore it is a step that has to be executed after running the fmriprep pipeline.\n\nSmoothing has been ommited by design. The fmriprep does not make assumption on how you are going to analyze your data\n\ne.g. Some MVPA studies do not do any smoothing at all before the first level analysis\n\nThe amount of smoothing is a matter of judgement\n\nExperiments that are focused on larger cortical areas, probably want to use larger smoothing kernels\n\n\nTip: Since we have multiple tasks with different goals, smoothing should be executed with this in mind and probably individually for each task/goal. When performing that use a prefix (e.g. smo0.8 or sth along those lines) in the name of the data so it is quite clear and easy to find what was the smoothing!",
    "crumbs": [
      "fMRIPrep",
      "fMRIPrep visual reports"
    ]
  },
  {
    "objectID": "IQMs_individual.html",
    "href": "IQMs_individual.html",
    "title": "Image Quality Metrics Individual level",
    "section": "",
    "text": "Introduction\nBased on the email exchange with Jerome Prado and Charlotte Constant, we can use the following toolbox to set a threshold for IQMs of interest [median ± 2.5 x (75% quartile-25% quartile)] that we calculate with API data and then compare it to IQMs of the participants. They did that to group level, but after discussing with Charlotte we can do it to individual level as well.\nThe only obstacle is that in the group level there is a .csv file with the IQMs, but in the individual level we have to extract the IQMs from the html file.\n\n\nIQMs extraction\nPython code to extract the IQMs from the html file:\nThis script can be found in the followig path: /Volumes/psyr2/Anastasios/Tiger_fmri/Tiger/code/mriqc_html_checks.py\nFor more information on how to run the script, see the script documentation.\n\n\nmriqc_html_checks.py\n\n#!/usr/bin/env python3\n\n\"\"\"\nTitle: Check MRIQC HTML files metrics checks\nAuthor: Anastasios Dadiotis\nDate created: 18/04/2024\nDate last modified: 18/04/2024\nPython Version: 3.9\n\"\"\"\n\"\"\"\nThis script will check the MRIQC HTML files for the metrics checks. It will extract the data from the tables and check if the values are \nwithin the expected range. \nIf the values are within the expected range, it will update the Checks.csv file with the results. \nIf the values are not within the expected range, it will write the results to a file for further investigation.\nIt can be used as main script or as a module to be imported in other scripts.\nIf run as a main script, it will take the working directory, the study name and the subject ID as arguments.\n\"\"\"\n\nimport os \nfrom bs4 import BeautifulSoup\nimport sys\nimport lxml.html as html\nimport pandas as pd\nimport html5lib\n\n# =============================================================================\n# Helper functions\n# =============================================================================\n\ndef load_and_parse_html(file_path):\n    \"\"\"\n    Load and parse an HTML file.\n    \n    Parameters\n    ----------\n    file_path : str\n        The path to the HTML file.\n        \n    Returns\n    -------\n    BeautifulSoup object\n        The parsed HTML content.\n    \n    Raises\n    ------\n    Exception\n        If an error occurs while processing the file.\n    \"\"\"\n    try:\n        with open(file_path, 'r') as file:\n            html_content = file.read()\n        soup = BeautifulSoup(html_content, 'lxml')\n        return soup\n    except Exception as e:\n        print(f\"An error occurred while processing{file_path}: {e}\")\n        return None\n\ndef extract_table_data(soup, table_id):\n    \"\"\"\n    Extract data from a table in an HTML file.\n    \n    Parameters\n    ----------\n    soup : BeautifulSoup object\n        The parsed HTML content.\n    table_id : str\n        The id of the table to extract the data from.\n        \n    Returns\n    -------\n    list\n        A list of lists containing the data from the table.\n\n    Raises\n    ------\n    Exception\n        If an error occurs while extracting data from the table.\n\n    Notes: if the table is not found, the function will return an empty list.\n    \"\"\"\n    try:\n        table = soup.find('table', id=table_id)\n        # Initialize an empty list to store your data\n        data = []\n        # Check if the table was found\n        if table:\n            rows = table.find_all('tr')\n            for row in rows:\n                cols = [td.get_text(strip=True) for td in row.find_all('td')]\n                if cols:\n                    data.append(cols)\n        return data\n    except Exception as e:\n        print(f\"An error occurred while extracting data from the table: {e}\")\n        return None\n    \n\ndef df_from_list(table_list):\n    \"\"\"\n    Create a pandas DataFrame from a list of lists extracted from an HTML table. IF subtitles are missing, they will be added as empty strings.\n    \n    Parameters\n    ----------\n    table_list : list\n        A list of lists containing the data to be converted to a DataFrame.\n        \n    Returns\n    -------\n    pandas.DataFrame\n        A DataFrame containing the data from the list of lists.\n    \"\"\"\n\n    for list in table_list:\n        if len(list) == 2:\n            list.insert(1, \"\")\n            list.insert(2, \"\")\n        elif len(list) == 3:\n            list.insert(2, \"\")\n        elif len(list) == 4:\n            continue\n        else:\n            print(\"Error in the table\")\n            break\n\n\n    # Create a pandas DataFrame from the table data\n    df = pd.DataFrame(table_list, columns=['Metric', 'Subtitle_1', 'Subtitle_2', 'Value'])\n    return df\n\n\n# =============================================================================\n# Variable definitions\n# To be replaced with sys.argv later\n# =============================================================================\n\n# Define the directory path\n# will use sys.argv for those variables later\nWD=\"/crnldata/psyr2/Anastasios/Tiger_fmri\"\nmy_study=\"Tiger\"\nsubject=\"CO1\"\n\n# Build the path to the mriqc html files\ndirectory_path = f'/Volumes/{WD}/{my_study}/data/bids/derivatives/mriqc' # NOTE: Volumes to be removed to run on the server!!!\n\n\n# =============================================================================\n# Main script\n# =============================================================================\n\n# get all the files in the directory to be able to loop through them later NOTE: to do after everything is working fine\n\nfile = \"sub-CO1_ses-S01_task-BigBuckBunny_echo-1_bold.html\" # just for testing, will not be hardcoded in the final version\n\nfilepath = f'{directory_path}/{file}'\n\n\n# Load and parse the HTML file\nsoup = load_and_parse_html(filepath)\n\ntable_list_test = extract_table_data(soup, 'about-metadata-table-2')\n\n# to be removed after testing\nprint(table_list_test)\n\ndf_test = df_from_list(table_list_test)\n\n# to be removed after testing\nprint(df_test)\n\n# TODO: Go over the metrics and check if they are within the expected range, if yes update the Checks.csv file with the results\n# if not write the results to a file for further investigation \n\n\n\nToDO\n\nFind the expected range for each metric from the API data given our parameters\nImplement that on the above scripts and add checks"
  },
  {
    "objectID": "fMRIPrep_visual_reports.html#todo",
    "href": "fMRIPrep_visual_reports.html#todo",
    "title": "fMRIPrep visual reports",
    "section": "ToDO",
    "text": "ToDO\n\nfix the video in normalization section as it is not working. Something with the codec",
    "crumbs": [
      "fMRIPrep",
      "fMRIPrep visual reports"
    ]
  },
  {
    "objectID": "Preprocessing.html",
    "href": "Preprocessing.html",
    "title": "Preprocessing",
    "section": "",
    "text": "Preprocessing does not end with fmriprep. We need to do some additional preprocessing steps to prepare the data for the analysis.\n\n\nfmriprep does not include smoothing. Smoothing is a preprocessing step that is often applied to fMRI data. It is used to increase the signal-to-noise ratio and to reduce the impact of individual differences in anatomy. Smoothing is done by applying a Gaussian filter to the data. The size of the filter is determined by the full-width at half-maximum (FWHM) parameter. The FWHM parameter specifies the width of the Gaussian filter in millimeters. The larger the FWHM, the more smoothing is applied to the data.\n\n\nNext chunk submit a job to the cluster to smooth the data using FSL.\nIn this script no set up is required as i have incorporated to the script. Just cd in the code directory and run the following command passing the relevant arguments.\nsbatch step06_smoothing.sh &lt;subject&gt; &lt;sigma&gt; &lt;prefix&gt;\nsqueue",
    "crumbs": [
      "Analyses",
      "Preprocessing"
    ]
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Analysis overview",
    "section": "",
    "text": "Intro\nThis section will have the code for doing all the steps in the analysis.\nPossible way to divide this section is in the following steps:\n1. Preprocessing + checks (MRIQC, fMRIPrep) Probably the cleanest way is to have guides and bash scripts fully visible each step (for easy copy pasting) but also have the python scripts in chunks that are folded, in case i want to inspect them.\n2. First level analysis (FSL)\n3. Second level analysis (FSL)\nOther stuff that could be included: - My notes on how to use the HPC",
    "crumbs": [
      "Analyses",
      "Analyses overview"
    ]
  },
  {
    "objectID": "multi_echo.html",
    "href": "multi_echo.html",
    "title": "Multi - Echo",
    "section": "",
    "text": "https://tedana.readthedocs.io/en/latest/index.html\nMost of the notes in this document are based on the above toolbox, which is also the toolbox that is used by default in fmriprep pipeline.",
    "crumbs": [
      "Technical notes",
      "Multi - Echo"
    ]
  },
  {
    "objectID": "multi_echo.html#section",
    "href": "multi_echo.html#section",
    "title": "Multi - Echo",
    "section": "",
    "text": "What is multi-echo fmri?\n\nTE (echo time): the time between triggering the Protons and capturing the information they decay.\nCollecting data at multiple echo times, resulting in multiple volumes with varying levels of contrast acquired per RF pulse.\nMulti - echo fmri is obtained by acquiring multi echo times (TE) for each MRI volume during data collection."
  },
  {
    "objectID": "multi_echo.html#why-use-multi--echo",
    "href": "multi_echo.html#why-use-multi--echo",
    "title": "Multi - Echo",
    "section": "Why use multi -echo ?",
    "text": "Why use multi -echo ?\n\nCompare results across different echoes\nCombine the results by weighted averaging: Rather than analsysing single -echo time series separately, we can combine them into  an “optimally combined time series\n\nOptimally combined data exhibit\n\nHigher SNR\nImproves statistical power of analyses in regions traditionally affected by drop-out\n\n\nDenoise the data based on information contained in the echoes\n\nUse the information available only when looking at signal decay across multiple TEs.",
    "crumbs": [
      "Technical notes",
      "Multi - Echo"
    ]
  },
  {
    "objectID": "multi_echo.html#costs-and-benefits-of-multi-echo-fmri",
    "href": "multi_echo.html#costs-and-benefits-of-multi-echo-fmri",
    "title": "Multi - Echo",
    "section": "Cost’s and benefits of multi echo fmri",
    "text": "Cost’s and benefits of multi echo fmri\n\nA slight time cost.\n\nFor ME fmri, the shortest Echo time is free since it’s collected in the gap between the RF pulse and the single - echo.\nSecond echo tends to roughly much the single-echo TE.\nAdditional echoes require more time\nFor example, on a 3T MRI, if the T2* weighted TE is 30ms for single echo fMRI, a multi-echo sequence may have TEs of 15.4, 29.7, and 44.0ms. In this example, the extra 14ms of acquisition time per RF pulse is the cost of multi-echo fMRI.\n\nWeighted average may lead to an increase in SNR\n\nA weighted average of the echoes to optimize T2* weighting (sometimes called optimally combined) gives a reliable, modest boost in data quality.\n\nConsider the life of the dataset\n\nIf a data set is expected to be used for future analyses in later years, it is likely that more powerful approaches to multi-echo denoising will sufficiently mature and add even more value to a data set.\n\nYou may recover signal in areas affected by dropout.\n\nTypical signal echo fmri uses an echo time that is appropriate for signal across most of the brain.\nThis might lead to drop out in regions with low T2* values –&gt; This can lead to lo or even no signal at all in some areas.\nThing of regions such as:\n\nOrbitofrontal cortex\nVentral temporal cortex\nVentral striatum",
    "crumbs": [
      "Technical notes",
      "Multi - Echo"
    ]
  },
  {
    "objectID": "multi_echo.html#multi---echo-fmri-sequences",
    "href": "multi_echo.html#multi---echo-fmri-sequences",
    "title": "Multi - Echo",
    "section": "Multi - echo fMRI sequences",
    "text": "Multi - echo fMRI sequences\n\nFor information about ME - fmri sequences with different scanners see:",
    "crumbs": [
      "Technical notes",
      "Multi - Echo"
    ]
  },
  {
    "objectID": "multi_echo.html#acquisition-parameter-recommendations",
    "href": "multi_echo.html#acquisition-parameter-recommendations",
    "title": "Multi - Echo",
    "section": "Acquisition parameter recommendations",
    "text": "Acquisition parameter recommendations\nA minimumof 3 echoes is required for running the current implementation fo TE-dependent denoising in tedana. It may be useful to have at least one echo that is earlier and one echo that is later than the TE one would use for single-echo T2* weighted fMRI.\nNote:\nThis is in contrast to the dual echo denoising method which uses a very early (~5ms) first echo in order to clean data.",
    "crumbs": [
      "Technical notes",
      "Multi - Echo"
    ]
  },
  {
    "objectID": "multi_echo.html#tendana-combination-method",
    "href": "multi_echo.html#tendana-combination-method",
    "title": "Multi - Echo",
    "section": "Tendana combination method",
    "text": "Tendana combination method\nUsing the T2*estimates, tedana combines signal across echoes using a weighted average. The echoes are weighted according to the formula\n\nThe weights are then normalized across echoes. These normalized weights are then used to compute a weighted average that takes advantage of the higher signal in earlier echoes and the higher sensitivity at later echoes."
  },
  {
    "objectID": "Techincal_stuff_intro.html",
    "href": "Techincal_stuff_intro.html",
    "title": "Technical stuff",
    "section": "",
    "text": "Notes on some technical stuff that might be useful."
  },
  {
    "objectID": "Techincal_stuff_intro.html#intro",
    "href": "Techincal_stuff_intro.html#intro",
    "title": "Technical stuff",
    "section": "",
    "text": "Notes on some technical stuff that might be useful."
  },
  {
    "objectID": "Technical_stuff_intro.html",
    "href": "Technical_stuff_intro.html",
    "title": "Technical stuff",
    "section": "",
    "text": "Notes on some technical things (like multi-echo acquisitions) that might be useful.",
    "crumbs": [
      "Technical notes",
      "Introduction"
    ]
  },
  {
    "objectID": "Technical_stuff_intro.html#intro",
    "href": "Technical_stuff_intro.html#intro",
    "title": "Technical stuff",
    "section": "",
    "text": "Notes on some technical things (like multi-echo acquisitions) that might be useful.",
    "crumbs": [
      "Technical notes",
      "Introduction"
    ]
  },
  {
    "objectID": "multi_echo.html#introduction",
    "href": "multi_echo.html#introduction",
    "title": "Multi - Echo",
    "section": "",
    "text": "https://tedana.readthedocs.io/en/latest/index.html\nMost of the notes in this document are based on the above toolbox, which is also the toolbox that is used by default in fmriprep pipeline.",
    "crumbs": [
      "Technical notes",
      "Multi - Echo"
    ]
  },
  {
    "objectID": "multi_echo.html#what-is-multi-echo-fmri",
    "href": "multi_echo.html#what-is-multi-echo-fmri",
    "title": "Multi - Echo",
    "section": "What is multi-echo fmri?",
    "text": "What is multi-echo fmri?\n\nTE (echo time): the time between triggering the Protons and capturing the information they decay.\nCollecting data at multiple echo times, resulting in multiple volumes with varying levels of contrast acquired per RF pulse.\nMulti - echo fmri is obtained by acquiring multi-echo times (TE) for each MRI volume during data collection.",
    "crumbs": [
      "Technical notes",
      "Multi - Echo"
    ]
  },
  {
    "objectID": "multi_echo.html#tedana-combination-method",
    "href": "multi_echo.html#tedana-combination-method",
    "title": "Multi - Echo",
    "section": "Tedana combination method",
    "text": "Tedana combination method\nUsing the T2*estimates, tedana combines signal across echoes using a weighted average. The echoes are weighted according to the formula\n\nThe weights are then normalized across echoes. These normalized weights are then used to compute a weighted average that takes advantage of the higher signal in earlier echoes and the higher sensitivity at later echoes.",
    "crumbs": [
      "Technical notes",
      "Multi - Echo"
    ]
  },
  {
    "objectID": "fMRIPrep.html#introduction",
    "href": "fMRIPrep.html#introduction",
    "title": "fMRI preprocessing",
    "section": "Introduction",
    "text": "Introduction\nBelow there is a general introduction to the most common artifacts in MRI data. This is a general introduction and not specific to fMRIPrep.\nIt is based on https://bpb-us-e1.wpmucdn.com/websites.harvard.edu/dist/f/49/files/2022/09/CBS_MRI_Qualitative_Qualitity_Control_Manual.pdf\nArtifacts: Factors that can compromise data quality.\n\nOnly detectable by manually scrolling through each slide of RAW data to look for visible distortions\n\n\nExamples of MRI artifacts\n\nField of View (FOV) clipping anatomy\nWrapping\nSignal loss/Susceptibility Artifact\nRinging, Stripping, or Blurring (structural scans)\nGhosting\nRadio Frequency Noise/Spiking\nSignal Inhomogeneity\nMotion Slice Artifact (functional scans)\n\n\n\nWhat causes MRI artifacts?\n\nExperimenter Error\n\nField of View (FOV) positioned wrong -&gt; brain image clipped -&gt; Wrapping\nForgot to move all metal -&gt; signal loss -&gt; “Susceptibility artifact”\n\nSubject Motion\n\nRinging, Stripping or Blurring (in structural scans)\n“Motion Slice artifact” (in functional scans)\n\nProblems with the Scanner/Head Coil\n\nRadio Frequency Noise/Spiking\nSignal Inhomogeneity\n\nArtifacts from Image Reconstruction\n\nConsistent low-level “Ghosting”\nSome types of “Ringing” (e.g “Shadowed Arc Artifact” in structural scans”)",
    "crumbs": [
      "fMRIPrep",
      "fMRI preprocessing"
    ]
  },
  {
    "objectID": "Bids_conversion.html",
    "href": "Bids_conversion.html",
    "title": "Bids Conversion",
    "section": "",
    "text": "This document is a step-by-step guide on how to convert raw data from a study to BIDS format.1 The tool that is used here is HeuDiConv. The data used in this example is from the Tiger study and already downloaded from xnat (see - add link when right this thing). The data are in a dicom format. Running HeuDiConv is a 3 step procedure. Note that this procedure takes place to the crnl cluster so this code is to be used with the cluster terminal and slurm. Most of the code is written in bash, but there are some python scripts that needs to be modified manually for the Bids conversion.",
    "crumbs": [
      "Analyses",
      "BIDS conversion"
    ]
  },
  {
    "objectID": "Bids_conversion.html#setup",
    "href": "Bids_conversion.html#setup",
    "title": "Bids Conversion",
    "section": "Setup",
    "text": "Setup\nIn this preliminary step we setup and define our variables. Note from the code below, change the variable “subject” to the subject you are working on. The Tiger notation is C for controls and G for Gamblers, e.g. for the first control subject the notation is C01 and for the first gambler G01. The following procedure is to submit the job for one subject. (to be updated for more).\n# Standard variable for the Tiger study\nWD=/crnldata/psyr2/Anastasios/Tiger_fmri\nmy_study=Tiger\nsession_name=S01\n\n# change this to the subject you are working on\nsubject=XXX",
    "crumbs": [
      "Analyses",
      "BIDS conversion"
    ]
  },
  {
    "objectID": "Bids_conversion.html#footnotes",
    "href": "Bids_conversion.html#footnotes",
    "title": "Bids Conversion",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor an excellent tutorial for Bids conversion see.↩︎",
    "crumbs": [
      "Analyses",
      "BIDS conversion"
    ]
  },
  {
    "objectID": "Bids_conversion.html#step-1-generate-a-heuristic.py-file.",
    "href": "Bids_conversion.html#step-1-generate-a-heuristic.py-file.",
    "title": "Bids Conversion",
    "section": "Step 1: Generate a heuristic.py file.",
    "text": "Step 1: Generate a heuristic.py file.\nBy passing some path information and flags to HeuDiConv, you generate a heuristic (translation) file skeleton and some associated descriptor text files. These all get placed in a hidden directory, .heudiconv under the bids/derivatives directory.\ncd ${WD}/${my_study}/code\nsbatch step1_heudiconv.sh ${subject} ${session_name} ${WD} ${my_study} \nsqueue\nTo check that it worked the out_step1_*.log file should have finished with exit code 0. Also, go to the /crnldata/psyr2/Anastasios/Tiger_fmri/Tiger/data/bids/derivatives/.heudiconv/{subject}/info were 5 files should be created.\nNote that this is a hidden directory. To see it you need to type ls -a in the terminal. The file that we need for the next step is the dicominfo.tsv file.\nThis step takes around 15 to 20 minutes to finish.",
    "crumbs": [
      "Analyses",
      "BIDS conversion"
    ]
  },
  {
    "objectID": "Bids_conversion.html#step-2-modify-the-heuristic.py-file",
    "href": "Bids_conversion.html#step-2-modify-the-heuristic.py-file",
    "title": "Bids Conversion",
    "section": "Step 2: Modify the heuristic.py file",
    "text": "Step 2: Modify the heuristic.py file\nYou will modify the heuristic.py to specify BIDS output names and directories, and the input DICOM characteristics. Available input DICOM characteristics are listed in /.heudiconv/info/dicominfo.tsv.\nCheck the template of the heuristic.py file specifically for the Tiger study in the following path: /crnldata/psyr2/Anastasios/Tiger_fmri/Tiger/code/heuristic.py. This is the one you should modify based on the dicominfo.tsv file of the specific subject.\nThe template is almost ready. What you should modify are the following lines:\n\nLine 119 s.dim == XXXX\nLine 123 s.dim == XXXX\nLine 127 s.dim == XXXX\n\nThe rest should remain the shame. At the end of this page there is the the heuristic.py file for inspection if nececarry.",
    "crumbs": [
      "Analyses",
      "BIDS conversion"
    ]
  },
  {
    "objectID": "Bids_conversion.html#step-3-run-heudiconv",
    "href": "Bids_conversion.html#step-3-run-heudiconv",
    "title": "Bids Conversion",
    "section": "Step 3: Run HeuDiConv",
    "text": "Step 3: Run HeuDiConv\nNow that the heuristic.py file is ready we can run the HeuDiConv. Each time you run it, additional subdirectories are created under .heudiconv that record the details of each subject (and session) conversion. Detailed provenance information is retained in the .heudiconv hidden directory. The following code is to be run in the terminal.\ncd ${WD}/${my_study}/code\nchmod -R 770 .\nsbatch step3_heudiconv.sh ${subject} ${session_name} ${WD} ${my_study}\nsqueue",
    "crumbs": [
      "Analyses",
      "BIDS conversion"
    ]
  },
  {
    "objectID": "Bids_conversion.html#step-1-generate-a-heuristic.py-file.-1",
    "href": "Bids_conversion.html#step-1-generate-a-heuristic.py-file.-1",
    "title": "Bids Conversion",
    "section": "Step 1: Generate a heuristic.py file.",
    "text": "Step 1: Generate a heuristic.py file.\nBy passing some path information and flags to HeuDiConv, you generate a heuristic (translation) file skeleton and some associated descriptor text files. These all get placed in a hidden directory, .heudiconv under the bids/derivatives directory.\ncd ${WD}/${my_study}/code\nsbatch step1_heudiconv.sh ${subject} ${session_name} ${WD} ${my_study} \nsqueue\nTo check that it worked the out_step1_*.log file should have finished with exit code 0. Also, go to the /crnldata/psyr2/Anastasios/Tiger_fmri/Tiger/data/bids/derivatives/.heudiconv/{subject}/info were 5 files should be created.\nNote that this is a hidden directory. To see it you need to type ls -a in the terminal. The file that we need for the next step is the dicominfo.tsv file.\nThis step takes around 15 to 20 minutes to finish."
  },
  {
    "objectID": "Bids_conversion.html#step-2-modify-the-heuristic.py-file-1",
    "href": "Bids_conversion.html#step-2-modify-the-heuristic.py-file-1",
    "title": "Bids Conversion",
    "section": "Step 2: Modify the heuristic.py file",
    "text": "Step 2: Modify the heuristic.py file\nYou will modify the heuristic.py to specify BIDS output names and directories, and the input DICOM characteristics. Available input DICOM characteristics are listed in /.heudiconv/info/dicominfo.tsv.\nCheck the template of the heuristic.py file specifically for the Tiger study in the following path: /crnldata/psyr2/Anastasios/Tiger_fmri/Tiger/code/heuristic.py. This is the one you should modify based on the dicominfo.tsv file of the specific subject.\nThe template is almost ready. What you should modify are the following lines:\n\nLine 119 s.dim == XXXX\nLine 123 s.dim == XXXX\nLine 127 s.dim == XXXX\n\nThe rest should remain the shame. Below there is the the heuristic.py file for inspection"
  },
  {
    "objectID": "Bids_conversion.html#step-3-run-heudiconv-1",
    "href": "Bids_conversion.html#step-3-run-heudiconv-1",
    "title": "Bids Conversion",
    "section": "Step 3: Run HeuDiConv",
    "text": "Step 3: Run HeuDiConv\n```{.python filename = “heuristic.py” code-line-numbers=“true”}\nfrom future import annotations import logging from typing import Optional\nfrom heudiconv.utils import SeqInfo\nlgr = logging.getLogger(“heudiconv”)\ndef create_key( template: Optional[str], outtype: tuple[str, …] = (“nii.gz”,), annotation_classes: None = None, ) -&gt; tuple[str, tuple[str, …], None]: if template is None or not template: raise ValueError(“Template must be a valid format string”) return (template, outtype, annotation_classes)\ndef infotodict( seqinfo: list[SeqInfo], ) -&gt; dict[tuple[str, tuple[str, …], None], list[str]]: “““Heuristic evaluator for determining which runs belong where\nallowed template fields - follow python string module:\n\nitem: index within category\nsubject: participant id\nseqitem: run number during scanning\nsubindex: sub index within group\n\"\"\"\n\n# \"data\" creates sequential numbers which can be for naming sequences.\n# This is especially valuable if you run the same sequence multiple times at the scanner.\ndata = create_key('run-{item:03d}')\n\n# Anatomical images\n# Structural scans (anat specification): MUST end with \"T1w\" or \"T2w\" or \"FLAIR\" or \"T1map\"...\n# list: https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html#anatomy-imaging-data\nt1w = create_key('sub-{subject}/{session}/anat/sub-{subject}_{session}_T1w')\n\n# Functional images\n# Tasks, including movies (func specification): MUST contain \"task-\" in the name + \"bold\" or \"sbref\" or \"cbv\" or \"phase\" at the end\n# list: https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html#task-including-resting-state-imaging-data\n# For tasks and movies, we need to specify the task name in the file name and then all the tasks are in the func folder. \n\n# Big Buck Bunny task\nboldBigBuckBunny = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-BigBuckBunny_bold')\nboldBigBuckBunny_sbref = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-BigBuckBunny_sbref')\n\n# Hariri task\nboldHariri = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-Hariri_bold')\nboldHariri_sbref = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-Hariri_sbref')\n\n# Partly Cloudy task\nboldPartlyCloudy = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-PartlyCloudy_bold')\nboldPartlyCloudy_sbref = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-PartlyCloudy_sbref')   \n\n# Skewed gambling task NOTE: this task has multiple runs\nboldSkewedGambling = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-SkewedGambling_run-{item:02d}_bold')\nboldSkewedGambling_sbref = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-SkewedGambling_run-{item:02d}_sbref')\n\n\n# field maps (fmap specification): the file name must end with \"magnitude\" or \"phasediff\" and include the {subject}\n# specifications: https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html#fieldmap-data\nfmap_magn = create_key('sub-{subject}/{session}/fmap/sub-{subject}_{session}_magnitude')\nfmap_phase = create_key('sub-{subject}/{session}/fmap/sub-{subject}_{session}_phasediff')\n\n# Diffusion scans (dwi speccification): MUST end with \"dwi\"\n# specifications: https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html#diffusion-imaging-data\ndwi = create_key('sub-{subject}/{session}/dwi/sub-{subject}_{session}_acq-{acq}_dir-{dir}_dwi')\ndwi_sbref = create_key('sub-{subject}/{session}/dwi/sub-{subject}_{session}_acq-{acq}_dir-{dir}_sbref')\n\n\ninfo: dict[tuple[str, tuple[str, ...], None], list[str]] = {data: [],\n                                                            boldHariri: [],\n                                                            boldHariri_sbref: [],\n                                                            boldBigBuckBunny: [],\n                                                            boldBigBuckBunny_sbref: [],\n                                                            boldPartlyCloudy: [],\n                                                            boldPartlyCloudy_sbref: [],\n                                                            boldSkewedGambling: [],\n                                                            boldSkewedGambling_sbref: [],\n                                                            fmap_magn: [],\n                                                            fmap_phase: [],\n                                                            t1w: [],\n                                                            dwi: [],\n                                                            dwi_sbref: []\n                                                            }\n\nfor s in seqinfo:\n    \"\"\"\n    The namedtuple `s` contains the following fields:\n\n    * total_files_till_now\n    * example_dcm_file\n    * series_id\n    * dcm_dir_name\n    * unspecified2\n    * unspecified3\n    * dim1\n    * dim2\n    * dim3\n    * dim4\n    * TR\n    * TE\n    * protocol_name\n    * is_motion_corrected\n    * is_derived\n    * patient_id\n    * study_description\n    * referring_physician_name\n    * series_description\n    * image_type\n    \"\"\"\n    if (\"emotion\" in s.protocol_name and s.dim4 == 3) :\n        info[boldHariri_sbref].append(s.series_id)\n    if (\"emotion\" in s.protocol_name and s.dim4 == 1257) :\n        info[boldHariri].append(s.series_id)\n    if (\"film_1\" in s.protocol_name and s.dim4 == 3) :\n        info[boldBigBuckBunny_sbref].append(s.series_id)\n    if (\"film_1\" in s.protocol_name and s.dim4 == 999) :\n        info[boldBigBuckBunny].append(s.series_id)\n    if (\"film_2\" in s.protocol_name and s.dim4 == 3) :\n        info[boldPartlyCloudy_sbref].append(s.series_id)\n    if (\"film_2\" in s.protocol_name and s.dim4 == 726) :\n        info[boldPartlyCloudy].append(s.series_id)\n    if (\"gambling\" in s.protocol_name and s.dim4 == 3) :\n        info[boldSkewedGambling_sbref].append(s.series_id)\n    if (\"gambling\" in s.protocol_name and s.dim4 &gt; 1400 ) :\n        info[boldSkewedGambling].append(s.series_id)\n    if (\"gre_field_mapping\" in s.protocol_name and s.dim4 == 106):\n        info[fmap_magn].append(s.series_id)\n    if (\"gre_field_mapping\" in s.protocol_name and s.dim4 == 53):\n        info[fmap_phase].append(s.series_id)\n    if (\"T1_SAG\" in s.protocol_name) and ('NORM' in s.image_type) :\n        info[t1w].append(s.series_id)\n    if (\"dmri\" in s.protocol_name and \"b2700\" in s.series_description and \"PA\" in s.series_description and s.dim4 == 1):\n        info[dwi_sbref].append({\"item\": s.series_id, \"acq\": \"b2700\", 'dir': \"PA\"})\n    if (\"dmri\" in s.protocol_name and \"b2700\" in s.series_description and \"PA\" in s.series_description and s.dim4 == 151):\n        info[dwi].append({\"item\": s.series_id, \"acq\": \"b2700\", 'dir': \"PA\"})\n    if (\"dmri\" in s.protocol_name and \"b2700\" in s.series_description and \"AP\" in s.series_description and s.dim4 == 1):\n        info[dwi_sbref].append({\"item\": s.series_id, \"acq\": \"b2700\", 'dir': \"AP\"})\n    if (\"dmri\" in s.protocol_name and \"b2700\" in s.series_description and \"AP\" in s.series_description and s.dim4 == 151):\n        info[dwi].append({\"item\": s.series_id, \"acq\": \"b2700\", 'dir': \"AP\"})\n    if (\"dmri\" in s.protocol_name and \"b0\" in s.series_description and \"AP\" in s.series_description and s.dim4 == 1):\n        info[dwi_sbref].append({\"item\": s.series_id, \"acq\": \"b0\", 'dir': \"AP\"})\n    if (\"dmri\" in s.protocol_name and \"b0\" in s.series_description and \"AP\" in s.series_description and s.dim4 == 7):\n        info[dwi].append({\"item\": s.series_id, \"acq\": \"b0\", 'dir': \"AP\"})\n    if (\"dmri\" in s.protocol_name and \"b0\" in s.series_description and \"PA\" in s.series_description and s.dim4 == 1):\n        info[dwi_sbref].append({\"item\": s.series_id, \"acq\": \"b0\", 'dir': \"PA\"})\n    if (\"dmri\" in s.protocol_name and \"b0\" in s.series_description and \"PA\" in s.series_description and s.dim4 == 7):\n        info[dwi].append({\"item\": s.series_id, \"acq\": \"b0\", 'dir': \"PA\"})\nreturn info\n\n\n:::"
  },
  {
    "objectID": "Bids_conversion.html#step1_heudiconv.sh",
    "href": "Bids_conversion.html#step1_heudiconv.sh",
    "title": "Bids Conversion",
    "section": "step1_heudiconv.sh",
    "text": "step1_heudiconv.sh\n\n\nstep1_heudiconv.sh\n\n#!/bin/bash\n\n###############################\n### Original script from Arnaud Fournel, PhD, NeuroPop team, CRNL, Lyon\n### arnaud.fournel @ inserm.fr\n### \n### Adapted for the CRNL study\n### by Gaelle Leroux, PhD\n### and Isabelle Faillenot, PhD\n###\n### Autumn 2020, Lyon\n### gaelle.leroux @ cnrs.fr\n###\n### launched by: sbatch step1_heudiconv.sh ${subject} ${session_name} ${WD} ${my_study}\n###\n###############################\n#\n### The SBATCH directives (line 39 to be revised only):\n\n### Your job name displayed by the queue\n### use \"squeue\" command in a terminal to see it\n#SBATCH --job-name=HeuDC_1\n\n### Specify output and error files\n### %A for job array's master job allocation number\n### or %a for job array ID (index) number\n#SBATCH --output=out_step1_%A.log\n#SBATCH --error=err_step1_%A.log\n\n### Specify the number of tasks, CPU per task and buffer size to be used \n### (up to 4 CPU/task to reach optimal power)\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\n### The size of the participant table to be run\n###SBATCH --array=1-1\n\n### If you want to launch your script on a specific node of the cluser\n### If yes, uncomment the appropirate line(s) \n###SBATCH --exclude=node9\n###SBATCH --nodelist=node10\n\n# End of the SBATCH directives\n###############################\n#\n# Paths of the study\nsubject=$1\nsession_name=$2\nWD=$3\nmy_study=$4\nSTUDY=${WD}/${my_study}\nDATA_DIRECTORY=\"${STUDY}/data\"\n#\nHEUDICONV_SINGULARITY_IMG=\"/mnt/data/soft/Images/heudiconv_1.1.0.sif\"\n#\n## Comment: Parse the participants.tsv file and extract one subject ID from the line corresponding to this SLURM task.\n## Comment: 1 line below to uncomment if you want to launch the script for all the subjects listed in ${DATA_DIRECTORY}/participants.tsv\n#subject=$( sed -n -E \"$((${SLURM_ARRAY_TASK_ID} + 1))s/sub-(\\S*)\\&gt;.*/\\1/gp\" ${DATA_DIRECTORY}/participants.tsv )\n#\n# To be printed in the out_*.log file :\necho \"#########################################################################\"\necho \"User:\" $USER\necho \"#\"\necho \"SLURM_SUBMITING_DIRECTORY:\" $SLURM_SUBMIT_DIR\necho \"SLURM_JOB_NODELIST:\" $SLURM_NODELIST\necho \"SLURM_JOB_NAME:\" $SLURM_JOB_NAME\necho \"SLURM_JOB_ID:\" $SLURM_JOBID\necho \"SLURM_ARRAY_TASK_ID:\" $SLURM_ARRAY_TASK_ID\necho \"SLURM_NTASKS:\" $SLURM_NTASKS\necho \"#\"\necho \"Step 1: generation of text files using HeuDiConv\"\necho \"#\"\necho \"Subject processed:\" ${subject}\necho \"Session processed:\" ${session_name}\necho \"#\"\necho \"Job STARTED @ $(date)\"\necho \"#\"\n#\n# STEP 1/3: generate heuristic file based on a template file + 4 other text files\n# Submission to slurm and running the HeuDiConv singularity image\n#\n# Check the \"-d\" path (line 83) pointing at the dicom files\n#\n# Compose the command line\ncmd=\"srun singularity run \\\n    --cleanenv \\\n    -B ${DATA_DIRECTORY}:/base \\\n    ${HEUDICONV_SINGULARITY_IMG} \\\n    -d /base/dicom/{subject}/{session}/scans/*/resources/DICOM/files/*.??? \\\n    -s ${subject} \\\n    --ses ${session_name} \\\n    -f convertall \\\n    -c none \\\n    -o /base/bids/derivatives \\\n    --overwrite\"\n#\n# Setup done, run the command\necho Running task ${SLURM_ARRAY_TASK_ID}\necho \"Command line used (example of the last subject processed)\"\necho $cmd\n#\necho \"#\"\n#\neval $cmd\nexitcode=$?\n#\necho \"#\"\necho \"Job STOPPED @ $(date)\"\necho \"#\"\necho \"If STEP 1 successful: 5 text files were generated in\" ${STUDY}\"/data/bids/derivatives/.heudiconv/\"$1\"/info\"\necho \"#\"\necho \"Now, STEP 2: edit the empty file heuristitic.py just created and copy/paste it to\" ${STUDY}\"/code\"\necho \"#\"\necho \"An example of heuristic file for a study@primage is provided in\" ${STUDY}\"/code/heuristic_templates/heuristic.py\"\necho \"#########################################################################\"\necho \"#\"\n# For your information about step 2:\n# The heuristic file controls how information about the dicoms is used to convert to a file system layout (e.g., BIDS). \n# This is a python file that must have the function infotodict, which takes a single argument seqinfo.\n#\n# Output results to a table\necho \"sub-$subject  ${SLURM_ARRAY_TASK_ID} $exitcode\" &gt;&gt; ${SLURM_JOB_NAME}.step1.${SLURM_ARRAY_JOB_ID}.tsv\necho Finished tasks ${SLURM_ARRAY_TASK_ID} with exit code $exitcode\nexit $exitcode",
    "crumbs": [
      "Analyses",
      "BIDS conversion"
    ]
  },
  {
    "objectID": "Bids_conversion.html#heuristic.py",
    "href": "Bids_conversion.html#heuristic.py",
    "title": "Bids Conversion",
    "section": "heuristic.py",
    "text": "heuristic.py\n\n\nheuristic.py\n\nfrom __future__ import annotations\n\nimport logging\nfrom typing import Optional\n\nfrom heudiconv.utils import SeqInfo\n\nlgr = logging.getLogger(\"heudiconv\")\n\n\ndef create_key(\n    template: Optional[str],\n    outtype: tuple[str, ...] = (\"nii.gz\",),\n    annotation_classes: None = None,\n) -&gt; tuple[str, tuple[str, ...], None]:\n    if template is None or not template:\n        raise ValueError(\"Template must be a valid format string\")\n    return (template, outtype, annotation_classes)\n\n\ndef infotodict(\n    seqinfo: list[SeqInfo],\n) -&gt; dict[tuple[str, tuple[str, ...], None], list[str]]:\n    \"\"\"Heuristic evaluator for determining which runs belong where\n\n    allowed template fields - follow python string module:\n\n    item: index within category\n    subject: participant id\n    seqitem: run number during scanning\n    subindex: sub index within group\n    \"\"\"\n\n    # \"data\" creates sequential numbers which can be for naming sequences.\n    # This is especially valuable if you run the same sequence multiple times at the scanner.\n    data = create_key('run-{item:03d}')\n\n    # Anatomical images\n    # Structural scans (anat specification): MUST end with \"T1w\" or \"T2w\" or \"FLAIR\" or \"T1map\"...\n    # list: https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html#anatomy-imaging-data\n    t1w = create_key('sub-{subject}/{session}/anat/sub-{subject}_{session}_T1w')\n\n    # Functional images\n    # Tasks, including movies (func specification): MUST contain \"task-\" in the name + \"bold\" or \"sbref\" or \"cbv\" or \"phase\" at the end\n    # list: https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html#task-including-resting-state-imaging-data\n    # For tasks and movies, we need to specify the task name in the file name and then all the tasks are in the func folder. \n\n    # Big Buck Bunny task\n    boldBigBuckBunny = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-BigBuckBunny_bold')\n    boldBigBuckBunny_sbref = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-BigBuckBunny_sbref')\n\n    # Hariri task\n    boldHariri = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-Hariri_bold')\n    boldHariri_sbref = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-Hariri_sbref')\n\n    # Partly Cloudy task\n    boldPartlyCloudy = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-PartlyCloudy_bold')\n    boldPartlyCloudy_sbref = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-PartlyCloudy_sbref')   \n\n    # Skewed gambling task NOTE: this task has multiple runs\n    boldSkewedGambling = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-SkewedGambling_run-{item:02d}_bold')\n    boldSkewedGambling_sbref = create_key('sub-{subject}/{session}/func/sub-{subject}_{session}_task-SkewedGambling_run-{item:02d}_sbref')\n\n\n    # field maps (fmap specification): the file name must end with \"magnitude\" or \"phasediff\" and include the {subject}\n    # specifications: https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html#fieldmap-data\n    fmap_magn = create_key('sub-{subject}/{session}/fmap/sub-{subject}_{session}_magnitude')\n    fmap_phase = create_key('sub-{subject}/{session}/fmap/sub-{subject}_{session}_phasediff')\n\n    # Diffusion scans (dwi speccification): MUST end with \"dwi\"\n    # specifications: https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html#diffusion-imaging-data\n    dwi = create_key('sub-{subject}/{session}/dwi/sub-{subject}_{session}_acq-{acq}_dir-{dir}_dwi')\n    dwi_sbref = create_key('sub-{subject}/{session}/dwi/sub-{subject}_{session}_acq-{acq}_dir-{dir}_sbref')\n\n\n    info: dict[tuple[str, tuple[str, ...], None], list[str]] = {data: [],\n                                                                boldHariri: [],\n                                                                boldHariri_sbref: [],\n                                                                boldBigBuckBunny: [],\n                                                                boldBigBuckBunny_sbref: [],\n                                                                boldPartlyCloudy: [],\n                                                                boldPartlyCloudy_sbref: [],\n                                                                boldSkewedGambling: [],\n                                                                boldSkewedGambling_sbref: [],\n                                                                fmap_magn: [],\n                                                                fmap_phase: [],\n                                                                t1w: [],\n                                                                dwi: [],\n                                                                dwi_sbref: []\n                                                                }\n\n    for s in seqinfo:\n        \"\"\"\n        The namedtuple `s` contains the following fields:\n\n        * total_files_till_now\n        * example_dcm_file\n        * series_id\n        * dcm_dir_name\n        * unspecified2\n        * unspecified3\n        * dim1\n        * dim2\n        * dim3\n        * dim4\n        * TR\n        * TE\n        * protocol_name\n        * is_motion_corrected\n        * is_derived\n        * patient_id\n        * study_description\n        * referring_physician_name\n        * series_description\n        * image_type\n        \"\"\"\n        if (\"emotion\" in s.protocol_name and s.dim4 == 3) :\n            info[boldHariri_sbref].append(s.series_id)\n        if (\"emotion\" in s.protocol_name and s.dim4 == 1257) :\n            info[boldHariri].append(s.series_id)\n        if (\"film_1\" in s.protocol_name and s.dim4 == 3) :\n            info[boldBigBuckBunny_sbref].append(s.series_id)\n        if (\"film_1\" in s.protocol_name and s.dim4 == 999) :\n            info[boldBigBuckBunny].append(s.series_id)\n        if (\"film_2\" in s.protocol_name and s.dim4 == 3) :\n            info[boldPartlyCloudy_sbref].append(s.series_id)\n        if (\"film_2\" in s.protocol_name and s.dim4 == 726) :\n            info[boldPartlyCloudy].append(s.series_id)\n        if (\"gambling\" in s.protocol_name and s.dim4 == 3) :\n            info[boldSkewedGambling_sbref].append(s.series_id)\n        if (\"gambling\" in s.protocol_name and s.dim4 &gt; 1400 ) :\n            info[boldSkewedGambling].append(s.series_id)\n        if (\"gre_field_mapping\" in s.protocol_name and s.dim4 == 106):\n            info[fmap_magn].append(s.series_id)\n        if (\"gre_field_mapping\" in s.protocol_name and s.dim4 == 53):\n            info[fmap_phase].append(s.series_id)\n        if (\"T1_SAG\" in s.protocol_name) and ('NORM' in s.image_type) :\n            info[t1w].append(s.series_id)\n        if (\"dmri\" in s.protocol_name and \"b2700\" in s.series_description and \"PA\" in s.series_description and s.dim4 == 1):\n            info[dwi_sbref].append({\"item\": s.series_id, \"acq\": \"b2700\", 'dir': \"PA\"})\n        if (\"dmri\" in s.protocol_name and \"b2700\" in s.series_description and \"PA\" in s.series_description and s.dim4 == 151):\n            info[dwi].append({\"item\": s.series_id, \"acq\": \"b2700\", 'dir': \"PA\"})\n        if (\"dmri\" in s.protocol_name and \"b2700\" in s.series_description and \"AP\" in s.series_description and s.dim4 == 1):\n            info[dwi_sbref].append({\"item\": s.series_id, \"acq\": \"b2700\", 'dir': \"AP\"})\n        if (\"dmri\" in s.protocol_name and \"b2700\" in s.series_description and \"AP\" in s.series_description and s.dim4 == 151):\n            info[dwi].append({\"item\": s.series_id, \"acq\": \"b2700\", 'dir': \"AP\"})\n        if (\"dmri\" in s.protocol_name and \"b0\" in s.series_description and \"AP\" in s.series_description and s.dim4 == 1):\n            info[dwi_sbref].append({\"item\": s.series_id, \"acq\": \"b0\", 'dir': \"AP\"})\n        if (\"dmri\" in s.protocol_name and \"b0\" in s.series_description and \"AP\" in s.series_description and s.dim4 == 7):\n            info[dwi].append({\"item\": s.series_id, \"acq\": \"b0\", 'dir': \"AP\"})\n        if (\"dmri\" in s.protocol_name and \"b0\" in s.series_description and \"PA\" in s.series_description and s.dim4 == 1):\n            info[dwi_sbref].append({\"item\": s.series_id, \"acq\": \"b0\", 'dir': \"PA\"})\n        if (\"dmri\" in s.protocol_name and \"b0\" in s.series_description and \"PA\" in s.series_description and s.dim4 == 7):\n            info[dwi].append({\"item\": s.series_id, \"acq\": \"b0\", 'dir': \"PA\"})\n    return info",
    "crumbs": [
      "Analyses",
      "BIDS conversion"
    ]
  },
  {
    "objectID": "Bids_conversion.html#step3_heudiconv.sh",
    "href": "Bids_conversion.html#step3_heudiconv.sh",
    "title": "Bids Conversion",
    "section": "step3_heudiconv.sh",
    "text": "step3_heudiconv.sh\n\n\nstep3_heudiconv.sh\n\n#!/bin/bash\n\n###############################\n### Original script from Arnaud Fournel, PhD, NeuroPop team, CRNL, Lyon\n### arnaud.fournel @ inserm.fr\n### \n### Adapted for the CRNL study\n### by Gaelle Leroux, PhD\n### and Isabelle Faillenot, PhD\n###\n### Autumn 2020, Lyon\n### gaelle.leroux @ cnrs.fr\n###\n### launched by: sbatch step3_heudiconv.sh ${subject} ${session_name} ${WD} ${my_study}\n###\n###############################\n#\n### The SBATCH directives (line 39 to be revised only):\n\n### Your job name displayed by the queue\n### use \"squeue\" command in a terminal to see it\n#SBATCH --job-name=HeuDC_3\n\n### Specify output and error files\n### %A for job array's master job allocation number.\n### or %a for job array ID (index) number\n#SBATCH --output=out_step3_%A.log\n#SBATCH --error=err_step3_%A.log\n\n### Specify the number of tasks, CPU per task and buffer size to be used\n### (up to 4 CPU/task to reach optimal power)\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=10G\n\n### Send email for which step: NONE, BEGIN, END, FAIL, REQUEUE, ALL\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=${firstName}.${lastName}@univ-lyon1.fr\n\n### The size of the participant table to be run\n### SBATCH --array=1-1\n\n### If you want to launch your script on a specific node of the cluser\n### If yes, uncomment the appropirate line(s) \n###SBATCH --exclude=node9\n###SBATCH --nodelist=node10\n\n# End of the SBATCH directives\n###############################\n#\n# Paths of the study\nsubject=$1\nsession_name=$2\nWD=$3\nmy_study=$4\nSTUDY=${WD}/${my_study}\nDATA_DIRECTORY=\"${STUDY}/data\"\nrm ${STUDY}/data/bids/${subject}/${session_name}/.heudiconv/*.edit.txt\n#\nHEUDICONV_SINGULARITY_IMG=\"/mnt/data/soft/Images/heudiconv_1.1.0.sif\"\n#\n## Comment: Parse the participants.tsv file and extract one subject ID from the line corresponding to this SLURM task.\n## Comment: 1 line below to uncomment if you want to launch the script for all the subjects listed in ${DATA_DIRECTORY}/participants.tsv\n#subject=$( sed -n -E \"$((${SLURM_ARRAY_TASK_ID} + 1))s/sub-(\\S*)\\&gt;.*/\\1/gp\" ${DATA_DIRECTORY}/participants.tsv )\n#\n# To be printed in the out_*.log file :\necho \"#########################################################################\"\necho \"User:\" $USER\necho \"#\"\necho \"SLURM_SUBMITING_DIRECTORY:\" $SLURM_SUBMIT_DIR\necho \"SLURM_JOB_NODELIST:\" $SLURM_NODELIST\necho \"SLURM_JOB_NAME:\" $SLURM_JOB_NAME\necho \"SLURM_JOB_ID:\" $SLURM_JOBID\necho \"SLURM_ARRAY_TASK_ID:\" $SLURM_ARRAY_TASK_ID\necho \"SLURM_NTASKS:\" $SLURM_NTASKS\necho \"#\"\necho \"Step 3: conversion of DICOM to NIFTI with BIDS standards using HeuDiConv\"\necho \"#\"\necho \"Subject processed:\" ${subject}\necho \"Session processed:\" ${session_name}\necho \"#\"\necho \"Job STARTED @ $(date)\"heuristic.py\necho \"#\"\n#\n# STEP 3/3: conversion of DICOM to NIFTII using dcm2niix and to a BIDS standard organisation\n# submission to slurm and running the HeuDiCon singularity image\n#\n# Check the \"-d\" path (line 87) pointing at the dicom files\n#\n# Compose the command line\ncmd=\"srun singularity run \\\n    --cleanenv \\\n    -B ${DATA_DIRECTORY}:/base -B ${STUDY}:/study \\\n    ${HEUDICONV_SINGULARITY_IMG} \\\n    -d /base/dicom/{subject}/{session}/scans/*/resources/DICOM/files/*.??? \\\n    -s ${subject} \\\n    --ses ${session_name} \\\n    -f /study/code/heuristic.py \\\n    -c dcm2niix -b \\\n    -o /base/bids \\\n    --minmeta \\\n    --overwrite\"\n#\n# Setup done, run the command\necho Running task ${SLURM_ARRAY_TASK_ID}\necho \"Command line used (example of the last subject processed)\"\necho $cmd\n#\necho \"#\"\n#\neval $cmd\nexitcode=$?\n#\necho \"#\"\necho \"Job STOPPED @ $(date)\"\necho \"#\"\necho \"If STEP 3 successful: check the text files & folders (.heudiconv and sub-{$1}) in\" \necho ${DATA_DIRECTORY}\"/bids\"\necho \"Edit the file\" ${DATA_DIRECTORY}\"/dataset_description.json\"\necho \"Create events.tsv file for each func/*.json file\"\necho \"#\"\necho \"Then, validate your nifti folder using online BIDS VALIDATOR: https://bids-standard.github.io/bids-validator/\"\necho \"############################################################################################\"\necho \"#\"\n# Output results to a table\necho \"sub-${subject}    ${SLURM_ARRAY_TASK_ID}  $exitcode\" &gt;&gt; ${SLURM_JOB_NAME}.step3.${SLURM_ARRAY_JOB_ID}.tsv\necho Finished tasks ${SLURM_ARRAY_TASK_ID} with exit code $exitcode\nexit $exitcode",
    "crumbs": [
      "Analyses",
      "BIDS conversion"
    ]
  },
  {
    "objectID": "run_mriqc.html",
    "href": "run_mriqc.html",
    "title": "Run MRIQC in CRNL cluster",
    "section": "",
    "text": "Set up\nIn this preliminary step we setup and define our variables. Note from the code below, change the variable “subject” to the subject you are working on. The Tiger notation is C for controls and G for Gamblers, e.g. for the first control subject the notation is C01 and for the first gambler G01. The following procedure is to submit the job for one subject. (to be updated for more).\n# Standard variable for the Tiger study\nWD=/crnldata/psyr2/Anastasios/Tiger_fmri\nmy_study=Tiger\nsession_name=S01\n\n# change this to the subject you are working on\nsubject=XXX \n\n\nSubmit the job\nRun the following code to submit the job to the cluster. This is for one subject only. There are scripts for multiple subjects via Slurm array jobs. (To be updated)\n# Submit the job\ncd ${WD}/${my_study}/code\nsbatch step4_mriqc.sh ${subject} ${session_name} ${WD} ${my_study}\nsqueue\n\n\nNotes and Errors\nI Run the job for the first time and i the job failed because it was out of memory. (exit code 137). I tried to increase the memory in the SBATCH directives in the step4_mriqc.sh file. I Tried with 100G. This did not work either Just for check i will run it for only the T1 images just to see what is going on. NOTE that the T1w are significantly smaller size that the bold. If this does not work then there is definetely a problem. So this run correctly, i will now try for the bold to see if only the bold will be executed. Bold job was again killed due to memory issues. What i will do next is to reduce to –nprocs 8 and –omp-nthreads 4 (This setup means MRIQC will not use more than 8 processes at a time, and each process will use up to 2 threads if multi-threading is supported by the task). NOTE: This might considerably slow down the job. Another solution would be to run MRIQC for each task seperetely as we did with T1w. To be checked\n\nWith these parameters above (–nprocs 8 and –omp-nthreads 4) it was executed succesfully. However, it took almost 2 hours for the bold images. It is worth trying submitting a unique job for each task in each modality as this could be faster. Another thing to try is play with the parameters. For instance, next we can try –nprocs 10 and –omp-nthreads 6 and if this works then double the original parameters\n\n\n\nScripts\n\n\nstep4_mriqc.sh\n\n#!/bin/bash\n\n###############################\n### from https://bircibrain.github.io/computingguide/docs/fmri-preprocessing/mriqc.html#singularitystorrs-hpc\n### \n### Adapted for the CRNL \n### by Gaelle Leroux, PhD\n### and Isabelle Faillenot, PhD\n###\n### Fall 2020, Lyon\n### gaelle.leroux @ cnrs.fr\n###\n### launched by: sbatch step4_mriqc.sh ${subject} ${session_name} ${WD} ${my_study}\n###\n###############################\n#\n### The SBATCH directives for a sequential (email line 37 to be revised only):\n\n### Your job name displayed by the queue\n### use \"squeue\" command in a terminal to see it\n#SBATCH --job-name=mriQC\n\n### Specify output and error files\n### %A for job array's master job allocation number\n### or %a for job array ID (index) number\n#SBATCH --output=out_mriQC_%A.log\n#SBATCH --error=err_mriQC_%A.log\n\n### Specify the number of tasks, CPU per task and buffer size to be used\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=100G\n\n\n### Send email for which step: NONE, BEGIN, END, FAIL, REQUEUE, ALL\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=${firstName}.${lastName}@univ-lyon1.fr\n\n### The size of the participant table to be run\n###SBATCH --array=1-1\n\n### If you want to launch your script on a specific node of the cluser\n### If yes, uncomment the appropirate line(s) \n###SBATCH --nodelist=node9\n#SBATCH --exclude=node9\n###SBATCH --exclude=node[9-10]\n\n# End of the SBATCH directives\n###############################\n#\n# Paths of the study\nsubject=$1\nsession_name=$2\nWD=$3\nmy_study=$4\nSTUDY=${WD}/${my_study}\nDATA_DIRECTORY=${STUDY}\"/data\"\nOUTPUT_DIRECTORY=${DATA_DIRECTORY}\"/bids\"\n#\nMRIQC_SINGULARITY_IMG=\"/mnt/data/soft/Images/mriqc_23.1.0.sif\"\n#\n## Comment: Parse the participants.tsv file and extract one subject ID from the line corresponding to this SLURM task.\n## Comment: 1 line below to uncomment if you want to launch the script for all the subjects listed in ${DATA_DIRECTORY}/participants.tsv\n#subject=$( sed -n -E \"$((${SLURM_ARRAY_TASK_ID} + 1))s/sub-(\\S*)\\&gt;.*/\\1/gp\" ${DATA_DIRECTORY}/participants.tsv )\n#\n###############################\n#\n# To be printed in the out_mriQC_*.log file :\necho \"#########################################################################\"\necho \"USER:\" $USER\necho \"#\"\necho \"SLURM_SUBMITING_DIRECTORY:\" $SLURM_SUBMIT_DIR\necho \"SLURM_JOB_NODELIST:\" $SLURM_NODELIST\necho \"SLURM_JOB_NAME:\" $SLURM_JOB_NAME\necho \"SLURM_JOB_ID:\" $SLURM_JOBID\necho \"SLURM_ARRAY_TASK_ID:\" $SLURM_ARRAY_TASK_ID\necho \"SLURM_NTASKS:\" $SLURM_NTASKS\necho \"#\"\necho \"Step 4: Control of the quality of images using mriQC BIDSapp\"\necho \"#\"\necho \"Subject:\" ${subject}\necho \"Session:\" ${session_name}\necho \"#\"\necho \"Job STARTED @ $(date)\"\necho \"#\"\n#\n# PREREQUISITE: a dataset organised according to BIDS standards.\n# NOW: submission to slurm workload manager and run a singularity image for mriQC \n#\n# Compose the command line\n#\n# Note that this is only for one modality for a check! REMEMBER to change it afterwards to run all modalities\n######## PLAYING WITH THE --nprocs and --omp-nthreads 4 to find the sweet spot remember to change that\n\n\ncmd=\"srun singularity run \\\n   --cleanenv \\\n   --bind ${STUDY}:/base --bind ${DATA_DIRECTORY}:/data --bind ${OUTPUT_DIRECTORY}:/out \\\n   ${MRIQC_SINGULARITY_IMG} \\\n   /data/bids /out/derivatives/mriqc participant \\\n   --participant-label ${subject} \\\n   --modalities bold \\\n   --work-dir /base/code/logs/mriqc_intermediate_results_${subject} \\\n   --mem 96 \\\n   --nprocs 8 \\\n   --omp-nthreads 4 \\\n   --profile \\\n   --verbose-reports \\\n   --write-graph \\\n   --fft-spikes-detector\"\n\n# Setup done, run the command\necho \"Command line used (example of the last subject processed)\"\necho $cmd\necho \"#\"\n#\neval $cmd\nexitcode=$?\n#\necho \"#\"\necho \"Job STOPPED @ $(date)\"\necho \"#\"\necho \"If MRIQC successful, the last end of the out*.log file is:\"\necho \"&lt;Participant level finished successfully&gt; Otherwise, a problem occured.\"\necho \"#\"\necho \"Check that \"$OUTPUT_DIRECTORY\"/derivatives/mriqc and mriqc_working_directory\"\necho \"folders have been created & look at all reports created.\"\necho \"############################################################################################\"\necho \"#\"\n# Output results to a table\necho \"sub-${subject}    ${SLURM_ARRAY_TASK_ID}  $exitcode\" &gt;&gt; ${SLURM_JOB_NAME}.step4.${SLURM_ARRAY_JOB_ID}.tsv\necho Finished tasks ${SLURM_ARRAY_TASK_ID} with exit code $exitcode\nexit $exitcode",
    "crumbs": [
      "MRIQC",
      "Run MRIQC in CRNL cluster"
    ]
  },
  {
    "objectID": "run_fmriprep.html",
    "href": "run_fmriprep.html",
    "title": "Run fmriprep in CRNL cluster",
    "section": "",
    "text": "Set up\nIn this preliminary step we setup and define our variables. Note from the code below, change the variable “subject” to the subject you are working on. The Tiger notation is C for controls and G for Gamblers, e.g. for the first control subject the notation is C01 and for the first gambler G01. The following procedure is to submit the job for one subject. (to be updated for more).\n# Standard variable for the Tiger study\nWD=/crnldata/psyr2/Anastasios/Tiger_fmri\nmy_study=Tiger\nsession_name=S01\n\n# change this to the subject you are working on\nsubject=XXX \n\n\nSubmit the job\nRun the following code to submit the job to the cluster. This is for one subject only. There are scripts for multiple subjects via Slurm array jobs. (To be updated)\nNeed step3 (see Bids) to be done ; mriqc is optional. To use fmap to make SDC, json files of fmap have to be change. See comment in step5_fmriprep.sh\n# Modify the 3 *.son files in the fmap directory\n\n# To add the \"IntendedFor\" field in the json files of the fieldmaps run the following command\nchmod -R 770 /crnldata/psyr2/Anastasios/Tiger_fmri/Tiger/data/bids/${subject}/ses-S01/fmap/ # This is extremelly important to have the right to write in the directory\n\n\ncd ${WD}/${my_study}/code\npython3 add_IntendedFor_Fieldmaps.py ${subject} # it is a very light job so i will run it in the frontal node instead of assigning it to other nodes. \n\n\n# Submit the job for one subject (to launch the job for a list of subjects, see the optional section at the end of this tutorial)\ncd ${WD}/${my_study}/code\nchmod -R 770 .\nchmod -R 770 ${WD}/${my_study}/data/bids/derivatives\nchmod -R 770 ${WD}/${my_study}/data/bids/derivatives/freesurfer-7.1.1 # to check \n\ncd ${WD}/${my_study}/code\nsbatch step5_fmriprep.sh ${subject} ${session_name} ${WD} ${my_study}\n\n\nScripts\n\nfmriprep\n\n\nstep5_fmriprep.sh\n\n#!/bin/bash\n\n#################################################\n### Original script from Arnaud Fournel, PhD, NeuroPop team, CRNL, Lyon\n### arnaud.fournel @ inserm.fr\n### and from \n### https://fmriprep.org/en/stable/singularity.html#running-singularity-on-a-slurm-system\n### \n### Adapted for the CRNL \n### by Gaelle Leroux, PhD\n### and Isabelle Faillenot, PhD\n###\n### Fall 2020, Lyon\n### gaelle.leroux @ cnrs.fr\n###\n### launched by: sbatch step5_fmriprep.sh ${subject} ${session_name} ${WD} ${my_study}\n###\n###############################\n#\n### The SBATCH directives (line 40 to be revised only):\n\n### Your job name displayed by the queue\n### use squeue command in a terminal to see it\n#SBATCH --job-name=fmriPrep\n\n### Specify output and error files\n### %A for job array's master job allocation number\n### or %a for job array ID (index) number\n#SBATCH --output=out_fmriPrep_%A.log\n#SBATCH --error=err_fmriPrep_%A.log\n\n### Specify the number of tasks, CPU per task and buffer size to be us\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=16\n### Changed the memory to 100G to avoid the code 137\n#SBATCH --mem=100G\n\n### Send email for which step: NONE, BEGIN, END, FAIL, REQUEUE, ALL\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=${firstName}.${lastName}@univ-lyon1.fr\n\n### The size of the participant table to be run\n###SBATCH --array=1-1\n\n### If you want to launch your script on a specific node of the cluser\n### If yes, uncomment the appropriate line(s) \n#SBATCH --exclude=node10\n###SBATCH --nodelist=node9\n\n# End of the SBATCH directives\n###############################\n#\n# Paths of the study\nsubject=$1\nsession_name=$2\nWD=$3\nmy_study=$4\nSTUDY=${WD}/${my_study}\nDATA_DIRECTORY=\"${STUDY}/data\"\n#\nFMRIPREP_SINGULARITY_IMG=\"/mnt/data/soft/Images/fmriprep_23.2.1.sif\"\n#\n## Comment: Parse the participants.tsv file and extract one subject ID from the line corresponding to this SLURM task.\n## Comment: 1 line below to uncomment if you want to launch the script for all the subjects listed in ${DATA_DIRECTORY}/participants.tsv\n#subject=$( sed -n -E \"$((${SLURM_ARRAY_TASK_ID} + 1))s/sub-(\\S*)\\&gt;.*/\\1/gp\" ${DATA_DIRECTORY}/participants.tsv )\n#\n# Definition of FreeSurfer env variables\nFREESURFER_HOME=${DATA_DIRECTORY}/bids/derivatives/freesurfer-7.1.1\nSINGULARITYENV_FREESURFER_HOME=${DATA_DIRECTORY}/bids/derivatives/freesurfer-7.1.1\n#\nSUBJECTS_DIR=${DATA_DIRECTORY}/bids/derivatives/freesurfer-7.1.1/subjects\nSINGULARITYENV_SUBJECTS_DIR=${DATA_DIRECTORY}/bids/derivatives/freesurfer-7.1.1/subjects\n#\nFS_LICENSE=${DATA_DIRECTORY}/bids/derivatives/freesurfer-7.1.1/license.txt\nSINGULARITYENV_FS_LICENSE=${DATA_DIRECTORY}/bids/derivatives/freesurfer-7.1.1/license.txt # Tells fMRIPrep the mount point\n#\nLOCAL_FREESURFER_DIR=${DATA_DIRECTORY}/bids/derivatives/freesurfer-7.1.1\n#\n# Prepare some writeable bind-mount points.\nTEMPLATEFLOW_HOME=${HOME}/.cache/templateflow\nSINGULARITYENV_TEMPLATEFLOW_HOME=${HOME}/.cache/templateflow # Tells fMRIPrep the mount point\nFMRIPREP_CACHE=${HOME}/.cache/fmriprep\nSINGULARITYENV_FMRIPREP_CACHE=${HOME}/.cache/fmriprep  # Tells fMRIPrep the mount point\nmkdir -p ${TEMPLATEFLOW_HOME}\nmkdir -p ${FMRIPREP_CACHE}\nmkdir -p ${DATA_DIRECTORY}/codes\n#\n###############################\n# To be printed in the out_fmriPrep_*.log file :\necho \"#########################################################################\"\necho \"USER:\" $USER\necho \"#\"\necho \"SLURM_SUBMITING_DIRECTORY:\" $SLURM_SUBMIT_DIR\necho \"SLURM_JOB_NODELIST:\" $SLURM_NODELIST\necho \"SLURM_JOB_NAME:\" $SLURM_JOB_NAME\necho \"SLURM_JOB_ID:\" $SLURM_JOBID\necho \"SLURM_ARRAY_TASK_ID:\" $SLURM_ARRAY_TASK_ID\necho \"SLURM_NTASKS:\" $SLURM_NTASKS\necho \"#\"\necho \"Step 5: fmriPrep is a preprocessing pipeline of fMRI data\"\necho \"#\"\necho \"Subject processed:\" ${subject}\necho \"Session processed:\" ${session_name}\necho \"#\"\necho \"Job STARTED @ $(date)\"\necho \"#\"\n#\n# PRE-REQUISTES: a dataset organised according to BIDS standards (using HeuDiConv or another tool).\n# Submission to slurm and running a singularity image fo fmriPrep \n# Compose the command line\n# options:\n#   --use-aroma  \\              to use ICA-aroma to separarte noise from signal (cf prium15)\n#   --use-syn-sdc \\             to have SDC but without fmap images\n#   --fd-spike-threshold 0.3 \\  to change the FD threshold to calculate motion_outliers (default = 0.5)\n#   --output-spaces MNI152NLin2009cSym:res-1 \\  to use a symetric template (available only in a cubic resolution of 1mm)\n# if you have fmap acquisition, and if you want to use them for the SDC : \n# in the files :data/bids/sub-XX/ses-ZZZ/*magnitude1.json + *magnitude2.json + *_phasediff.json\n# add at the end : \n# \"IntendedFor\": [\"ses-IRM/func/sub-XX_ses-ZZZ_task-YY_bold.nii.gz\",\n#                   \"ses-IRM/func/sub-XX_ses-ZZZ_task-YY_bold.nii.gz\"]\n#\ncmd=\"srun singularity run \\\n    --cleanenv \\\n    --bind ${DATA_DIRECTORY}:/data --bind ${LOCAL_FREESURFER_DIR}:/fsdir \\\n    ${FMRIPREP_SINGULARITY_IMG} \\\n    /data/bids /data/bids/derivatives/fmriprep participant \\\n    --participant-label ${subject} \\\n    --work-dir /data/codes \\\n    --low-mem \\\n    --stop-on-first-crash \\\n    --write-graph \\\n    --fs-license-file /fsdir/license.txt --fs-subjects-dir /fsdir\"\n#\n# Setup done, run the command\necho Running task ${SLURM_ARRAY_TASK_ID}\necho \"Command line used (example of the last subject processed)\"\necho $cmd\n#\necho \"#\"\n#\neval $cmd\nexitcode=$?\n#\necho \"#\"\necho \"Job STOPPED @ $(date)\"\necho \"#\"\necho \"If fmriPrep successful: it is clearly indicated in the out*.log file as\" \necho \"[...] fMRIPrep finished successfully! [...] otherwise, problem(s) occured.\"\necho \"############################################################################################\"\necho \"#\"\n# Output results to a table\n# code 137 : raise the --mem SBATCH directive\necho \"sub-${subject}    ${SLURM_ARRAY_TASK_ID}  $exitcode\" &gt;&gt; ${SLURM_JOB_NAME}.step5.${SLURM_ARRAY_JOB_ID}.tsv\necho Finished tasks ${SLURM_ARRAY_TASK_ID} with exit code $exitcode\nexit $exitcode\n\n\n\nfieldmaps\n\n\nadd_IntendedFor_Fieldmaps.py\n\n\"\"\"\nTitle: Script to add IntendedFor field to the json files of the fieldmaps\nAuthor: Anastasios Dadiotis\nDate created: 15/04/2024\nDate last modified: 15/04/2024\nDescription: This script will add the IntendedFor field to the json files of the fieldmaps. The IntendedFor field is a list of the functional images that the fieldmap is intended for. \nThis is recommended for the BIDS format but is necessary to Fieldmap correct within FMRIprep. \n\"\"\"\n\"\"\"\nUsage: This script is called from the bash with the following command:\npython add_IntendedFor_Fieldmaps.py ${subject}\nwhere subject is the participant id.\nNote: Before running the script make sure that you have rights to write in the directory where the json files are located.\nif not, you can change the permissions with the following command:\nchmod -R 770 /path/to/directory\n\"\"\"\n\n\n# Import the necessary libraries\nimport json\nimport os\nimport sys\n\n# Participants id from the bash script\nid = sys.argv[1]\n\n# Define the directory path\n#directory_path = f'/Volumes/psyr2/Anastasios/Tiger_fmri/Tiger/data/bids/sub-{id}/ses-S01/fmap'\ndirectory_path = f'/crnldata/psyr2/Anastasios/Tiger_fmri/Tiger/data/bids/sub-{id}/ses-S01/fmap'\n# load the json files of the fieldmaps\njson_files = [f for f in os.listdir(directory_path) if f.endswith('.json') and \"._\" not in f]\n\n# create the list of scans for the IntendedFor field\nIntendedFor = []\ntasks = [\"BigBuckBunny\", \"Hariri\", \"PartlyCloudy\", \"SkewedGambling\"]\n\n# loop over tasks, runs and echoes to create the list of scans for the IntendedFor field\nfor task in tasks:\n    if task != \"SkewedGambling\":\n        for echo in range (1,4):\n            IntendedFor.append(f\"ses-S01/func/sub-{id}_ses-S01_task-{task}_echo-{echo}_bold.nii.gz\")\n    elif task == \"SkewedGambling\":\n        for run in range(1,4):\n            for echo in range (1,4):\n                IntendedFor.append(f\"ses-S01/func/sub-{id}_ses-S01_task-{task}_run-0{run}_echo-{echo}_bold.nii.gz\")\n    else:\n        print(\"Error in the task name\")\n   \n\n    \n# loop over the json files and add the IntendedFor field\nfor json_file in json_files:\n    json_file_path = f'{directory_path}/{json_file}'\n    with open(json_file_path, 'r') as file:\n        data = json.load(file)\n        data[\"IntendedFor\"] = IntendedFor\n        with open(json_file_path, 'w') as file:\n            json.dump(data, file, indent=4)",
    "crumbs": [
      "fMRIPrep",
      "Run fmriprep in CRNL cluster"
    ]
  },
  {
    "objectID": "Preprocessing.html#smoothing",
    "href": "Preprocessing.html#smoothing",
    "title": "Preprocessing",
    "section": "",
    "text": "fmriprep does not include smoothing. Smoothing is a preprocessing step that is often applied to fMRI data. It is used to increase the signal-to-noise ratio and to reduce the impact of individual differences in anatomy. Smoothing is done by applying a Gaussian filter to the data. The size of the filter is determined by the full-width at half-maximum (FWHM) parameter. The FWHM parameter specifies the width of the Gaussian filter in millimeters. The larger the FWHM, the more smoothing is applied to the data.\n\n\nNext chunk submit a job to the cluster to smooth the data using FSL.\nIn this script no set up is required as i have incorporated to the script. Just cd in the code directory and run the following command passing the relevant arguments.\nsbatch step06_smoothing.sh &lt;subject&gt; &lt;sigma&gt; &lt;prefix&gt;\nsqueue",
    "crumbs": [
      "Analyses",
      "Preprocessing"
    ]
  }
]